title: # Human-like Controllable Image Captioning with Verb-specific Semantic Roles

authors: Long Chen<sup>2,3*,</sup>    Zhihong Jiang<sup>1*</sup>    Jun Xiao\({}^{1\dagger}\)   Wei Liu<sup>4</sup>

affiliations: <sup>1</sup>Zhejiang University   <sup>2</sup>Tencent AI Lab   <sup>3</sup>Columbia University   <sup>4</sup>Tencent Data Platform<br><br>zjuchenlong@gmail.com, {zju_jiangzhihong, junx}@zju.edu.cn, wl2223@columbia.edu<br><br>denotes equal contributions,   <sup>&dagger;</sup> denotes the corresponding author.

![img](img/0.png)
![img](img/1.png)
![img](img/2.png)
![img](img/3.png)
![img](img/4.png)
![img](img/5.png)
![img](img/6.png)
## abs
The paper introduces Controllable Image Captioning (CIC) and addresses the limitations of existing objective control signals by proposing a new control signal called Verb-specific Semantic Roles (VSR). VSR considers event-compatibility and sample-suitability and consists of a verb and semantic roles representing an activity and the roles of entities involved. The authors present a framework consisting of a grounded semantic role labeling (GSRL) model, a semantic structure planner (SSP), and a role-shift captioning model to generate captions based on VSR. Experimental results on COCO Entities and Flickr30K Entities demonstrate the effectiveness and controllability of the proposed framework. Future research directions include improving the captioning model, extending VSR to other tasks, and addressing images without verbs.
## intro
The paper introduces Controllable Image Captioning (CIC) and proposes a new control signal called Verb-specific Semantic Roles (VSR) to address the limitations of existing objective control signals. The VSR ensures event compatibility and sample suitability by including a verb and semantic roles. The proposed framework includes a grounded semantic role labeling (GSRL) model, a semantic structure planner (SSP), and a role-shift captioning model to generate captions based on the VSR. Extensive experiments demonstrate that the framework achieves better controllability and diversity compared to baseline models. Future research directions include improving the captioning model, extending VSR to other tasks, and designing a more general framework.
## related work
The paper proposes a new control signal, Verb-specific Semantic Roles (VSR), for Controllable Image Captioning (CIC). The VSR considers event-compatibility and sample-suitability, addressing limitations in existing objective control signals. The proposed framework includes a Grounded Semantic Role Labeling (GSRL) model, a Semantic Structure Planner (SSP), and a Role-shift Captioning model to generate captions based on the VSR. Extensive experiments on benchmark datasets demonstrate the effectiveness of the framework in achieving better controllability and generating diverse captions. However, the summary lacks specific details about the experimental results and performance metrics achieved. Future research directions include exploring more effective captioning models, extending VSR to other controllable text generation tasks, and designing a more general framework.
## 3 Proposed Approach
The paper proposes a new control signal called Verb-specific Semantic Roles (VSR) for Controllable Image Captioning (CIC). It addresses the limitations of existing objective control signals by considering event-compatibility and sample-suitability. The proposed framework includes a grounded semantic role labeling (GSRL) model, semantic structure planner (SSP), and role-shift captioning model. The paper provides limited details about these models, and further clarification is needed. Extensive experiments on COCO Entities and Flickr30K Entities datasets demonstrate the effectiveness of the proposed framework in achieving better controllability and generating diverse captions. However, the lack of quantitative measurements weakens the evaluation. Future work includes improving the captioning model, extending VSR to other tasks, and designing a more general framework for images without verbs.
## experiment
This paper proposes a novel control signal called Verb-specific Semantic Roles (VSR) for Controllable Image Captioning (CIC). The VSR ensures event-compatibility and sample-suitability by including a verb and semantic roles. The framework consists of a grounded semantic role labeling (GSRL) model, a semantic structure planner (SSP), and a role-shift captioning model. The proposed framework achieves better controllability and diversity compared to baselines on COCO Entities and Flickr30K Entities datasets. Future work includes improving the captioning model, extending VSR to other tasks, and designing a more general framework.
## conclusion
The paper proposes a novel control signal, Verb-specific Semantic Roles (VSR), for Controllable Image Captioning (CIC). The VSR ensures event-compatibility and sample-suitability by consisting of a verb and semantic roles. The framework includes a grounded semantic role labeling model, a semantic structure planner, and a role-shift captioning model. Extensive experiments on COCO Entities and Flickr30K Entities datasets demonstrate the effectiveness of the VSR-guided framework in achieving better controllability and generating diverse captions. Future work includes improving the captioning model, extending VSR to other text generation tasks, and designing a more general framework.
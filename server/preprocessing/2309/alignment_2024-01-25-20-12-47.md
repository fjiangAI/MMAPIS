# Human-like Controllable Image Captioning with Verb-specific Semantic Roles

- Authors: Long Chen<sup>2,3*,</sup>    Zhihong Jiang<sup>1*</sup>    Jun Xiao\({}^{1\dagger}\)   Wei Liu<sup>4</sup>

- Affiliations: <sup>1</sup>Zhejiang University   <sup>2</sup>Tencent AI Lab   <sup>3</sup>Columbia University   <sup>4</sup>Tencent Data Platform<br><br>zjuchenlong@gmail.com, {zju_jiangzhihong, junx}@zju.edu.cn, wl2223@columbia.edu<br><br>denotes equal contributions,   <sup>&dagger;</sup> denotes the corresponding author.

![img](img/Training and Inference_0.png)

![img](img/Evaluation on Controllability_0.png)

![img](img/Evaluation on Controllability_1.png)

![img](img/Evaluation on Controllability_2.png)

![img](img/Evaluation on Diversity_0.png)

![img](img/Evaluation on Diversity_1.png)

## Abstract
In this paper, a novel control signal called Verb-specific Semantic Roles (VSR) is proposed for Controllable Image Captioning (CIC). The VSR consists of a verb and semantic roles, ensuring event compatibility and sample suitability. The framework includes a grounded semantic role labeling (GSRL) model, a semantic structure planner (SSP), and a role-shift captioning model. Extensive experiments on COCO Entities and Flickr30K Entities datasets demonstrate the effectiveness of the VSR-guided framework in achieving better controllability and generating diverse captions. Future work includes improving the captioning model, extending VSR to other tasks, and developing a more general framework for images without verbs.
## Introduction
This paper introduces Verb-specific Semantic Roles (VSR) as a novel control signal for Controllable Image Captioning (CIC). The authors argue that existing control signals overlook the important characteristics of being event-compatible and sample-suitable. VSR consists of a verb and semantic roles, ensuring compatibility with the described activity and suitability for specific image samples. The proposed framework includes a grounded semantic role labeling (GSRL) model, a semantic structure planner (SSP), and a role-shift captioning model. Extensive experiments on COCO Entities and Flickr30K Entities datasets demonstrate the effectiveness of the proposed framework in achieving better controllability and generating diverse captions. Future work includes designing a more effective captioning model, extending VSR to other tasks, and developing a more general framework.
## Related Work
This paper proposes a new control signal, Verb-specific Semantic Roles (VSR), for controllable image captioning (CIC). The authors argue that existing control signals overlook essential characteristics such as event-compatibility and sample-suitability. VSR consists of a verb and semantic roles, ensuring event-compatibility and sample-suitability. The proposed framework achieves better controllability and generates diverse captions compared to strong baselines on benchmark datasets. Future work includes improving the captioning model, extending VSR to other text generation tasks, and designing a more general framework for images without verbs.
## 3 Proposed Approach
![img](img/Proposed Approach_0.png)

This paper introduces a novel control signal, Verb-specific Semantic Roles (VSR), for Controllable Image Captioning (CIC). The VSR consists of a verb and semantic roles, ensuring event-compatibility and sample-suitability. Extensive experiments on COCO Entities and Flickr30K Entities datasets demonstrate the effectiveness of the proposed framework in achieving better controllability and diversity in caption generation compared to baselines. Future work includes improving the captioning model, extending VSR to other text generation tasks, and designing a more general framework.
## Experiments
The paper introduces Controllable Image Captioning (CIC) and addresses the limitations of existing objective control signals by proposing a new control signal called Verb-specific Semantic Roles (VSR). VSR ensures event-compatibility and sample-suitability. The authors present the framework for the VSR-guided controllable image captioning model, which includes a Grounded Semantic Role Labeling (GSRL) model, a Semantic Structure Planner (SSP), and a Role-shift Caption Generation model. Extensive experiments on COCO Entities and Flickr30K Entities datasets demonstrate that the proposed framework achieves better controllability and generates diverse captions. Future research directions include improving the captioning model, extending VSR to other text generation tasks, and designing a more general framework.
## Conclusions & Future Works
The paper introduces Controllable Image Captioning (CIC) and proposes a new control signal called Verb-specific Semantic Roles (VSR) to improve controllability in generating captions. The VSR ensures event-compatibility and sample-suitability of mentioned entities. The framework includes grounded semantic role labeling, semantic structure planning, and role-shift caption generation. Experimental results on COCO Entities and Flickr30K Entities datasets demonstrate the effectiveness of the proposed framework in achieving better controllability and generating diverse captions. Future work includes improving the captioning model, extending VSR to other tasks, and designing a more general framework.
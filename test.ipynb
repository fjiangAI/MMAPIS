{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## logging 预处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "2023-11-04 18:41:42 - INFO - split_text.py:240 - article :None,parse author and affiliation without latex successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": "(False,\n title:## Abstract\n  text:We present results from a pilot experiment to measure if machine recommendations can debias human perceptual biases in visualization tasks. We specifically studied the \"pull-down\" effect, i.e., people underestimate the average position of lines [23], for the task of estimating the ensemble average of data points in line charts. These line charts can show for example temperature or precipitation in 12 months. Six participants estimated ensemble averages with or without an AI assistant. The assistant, when available, responded at three different speeds to assemble the conditions of a human collaborator who may delay his or her responses. Our pilot study showed that participants were faster with AI assistance in ensemble tasks, compared to the baseline without AI assistance. Although \"pull-down\" biases were reduced, the effect of AI assistance was not statistically significant. Also, delaying AI responses had no significant impact on human decision accuracy. We discuss the implications of these preliminary results for subsequent studies.\n \n **Index Terms:** Human-centered computing--Visualization--Visualization techniques--evaluation methods; Human-AI teaming--Pilot study--charts--biases;)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import yaml\n",
    "import json\n",
    "from submodule.openai_api import  Article\n",
    "from submodule.nougat_main import  nougat_predict\n",
    "from submodule.arxiv_links import get_arxiv_links\n",
    "import re\n",
    "import time\n",
    "from logging.config import fileConfig\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "logging_path = 'logging.ini'\n",
    "logging.config.fileConfig(logging_path)\n",
    "logger = logging.getLogger('applog')\n",
    "\n",
    "yaml_path = './config.yaml'\n",
    "with open(yaml_path, 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "openai_info = config[\"openai\"]\n",
    "with open(openai_info['prompts_path'], 'r') as f:\n",
    "    prompts= json.load(f)\n",
    "arxiv_info = config['arxiv']\n",
    "\n",
    "nougat_info = config[\"nougat\"]\n",
    "proxy = arxiv_info['proxy']\n",
    "headers = arxiv_info['headers']\n",
    "ignore_titles = openai_info['ignore_title']\n",
    "\n",
    "# md_path = './res/raw_mmd/2310_12169.mmd'\n",
    "md_path = './res/raw_mmd/2311_00706.mmd'\n",
    "with open(md_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "import re\n",
    "pattern = re.compile(r'#+\\s+Abstract')\n",
    "print(type(re.sub(pattern, r'## Abstract', text,1)))\n",
    "re.sub(pattern, r'## Abstract', text,1) == text.replace('######','##'),Article(text).groups[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'dsjaiodjasoijfojdifos---dasda'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'dsjaiodjasoijfojdifosdadasda'\n",
    "pattern = re.compile(r'da')\n",
    "re.sub(pattern, r'---', x, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## csv文件"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Zhe Ni<sup>dagger</sup>, Xiao-Xin Deng<sup>dagger</sup>, Cong Tai<sup>dagger</sup>, Xin-Yue Zhu, Xiang Wu, Yong-Jin Liu, Long Zeng<sup>*</sup><br><br>Project website: [https://jackyzengl.github.io/GRID.github.io/](https://jackyzengl.github.io/GRID.github.io/)<br><br><sup>dagger</sup>Equal contribution.<sup>*</sup>Corresponding author. (e-mail: zenglong@sz.tsinghua.edu.cn) Zhe Ni, Xiao-Xin Deng, Cong Tai, Xin-Yue Zhu, and Long Zeng are with Shenzhen International Graduate School, Tsinghua University, Shenzhen, China. Xiang Wu is with Shenzhen Phudu Technology Inc., Shenzhen, China. Yong-Jin Liu is with MOE Key Laboratory of Pervasive Computing, Department of Computer Science and Technology, Tsinghua University, Beijing, China.'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributor = \"\"\"Anwar Said\\\\\\\\({}^{\\\\\\\\dagger}\\\\\\\\), Mudassir Shabbir\\\\\\\\({}^{\\\\\\\\dagger}\\\\\\\\)\\\\\\\\({}^{\\\\\\\\lx@sectionsign}\\\\\\\\), Tyler Derr\\\\\\\\({}^{\\\\\\\\dagger}\\\\\\\\), Waseem Abbas\\\\\\\\({}^{\\\\\\\\ddagger}\\\\\\\\), Xenofon Koutsoukos\\\\\\\\({}^{\\\\\\\\dagger}\\\\\\\\)\\\\n\\\\n\\\\\\\\({}^{\\\\\\\\dagger}\\\\\\\\)Vanderbilt University, Nashville, TN, USA\\\\n\\\\n\\\\\\\\({}^{\\\\\\\\ddagger}\\\\\\\\)University of Texas at Dallas, Richardson, TX, USA\\\\n\\\\n\\\\\\\\({}^{\\\\\\\\lx@sectionsign}\\\\\\\\)Information Technology University, Lahore, Pakistan\\\\n\\\\nAnwar Said, Tyler Derr and Xenofon Koutsoukos are with the Computer Science Department at the Vanderbilt University, Nashville, TN. Emails: {anwar.said,yler.derr,x,xenofon.koutsoukos}@vanderbilt.edu.Waseem Abbas is with the Systems Engineering Department at the University of Texas at Dallas, Richardson, TX. Email: waseem.abbas@tudallas.eduMudassir Shabbir is with the Computer Science Department at Information Technology University, Lahore, Pakistan and with Vanderbilt University, Nashville, TN, USA. Email: mudassir.shabbir@itu.edu.pk.\\\\n\\\\n\"\"\"\n",
    "\n",
    "contributor2 = \"\"\"Zhe Ni\\({}^{\\dagger}\\), Xiao-Xin Deng\\({}^{\\dagger}\\), Cong Tai\\({}^{\\dagger}\\), Xin-Yue Zhu, Xiang Wu, Yong-Jin Liu, Long Zeng\\({}^{*}\\)\n",
    "\n",
    "Project website: [https://jackyzengl.github.io/GRID.github.io/](https://jackyzengl.github.io/GRID.github.io/)\n",
    "\n",
    "\\({}^{\\dagger}\\)Equal contribution.\\({}^{*}\\)Corresponding author. (e-mail: zenglong@sz.tsinghua.edu.cn) Zhe Ni, Xiao-Xin Deng, Cong Tai, Xin-Yue Zhu, and Long Zeng are with Shenzhen International Graduate School, Tsinghua University, Shenzhen, China. Xiang Wu is with Shenzhen Phudu Technology Inc., Shenzhen, China. Yong-Jin Liu is with MOE Key Laboratory of Pervasive Computing, Department of Computer Science and Technology, Tsinghua University, Beijing, China.\"\"\"\n",
    "\n",
    "# contributors = re.sub(r'\\\\+\\(\\{\\}\\^\\{\\\\*([^\\\\]*?)\\\\*\\}\\\\+\\)(\\\\+\\(\\{\\}\\^\\{([^\\\\]*?)\\}\\\\+\\))?', r'<sup>\\1,\\3</sup>', contributor2)\n",
    "contributors = re.sub(r'\\\\+\\(\\{\\}\\^\\{\\\\*([^\\\\]*?)\\\\*\\}\\\\+\\)(\\\\+\\(\\{\\}\\^\\{([^\\\\]*?)\\}\\\\+\\))?',r'<sup>\\1,\\3</sup>', contributor2)\n",
    "contributors = re.sub(r'>([^,]*?),<',r'>\\1<',contributors)\n",
    "contributors = re.sub(r'\\n', r'<br>', contributors)\n",
    "contributors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "('Zhe Ni<sup>dagger</sup>, Xiao-Xin Deng<sup>dagger</sup>, Cong Tai<sup>dagger</sup>, Xin-Yue Zhu, Xiang Wu, Yong-Jin Liu, Long Zeng<sup>*</sup><br><br>Project website: [https://jackyzengl.github.io/GRID.github.io/](https://jackyzengl.github.io/GRID.github.io/)',\n '<sup>dagger</sup>Equal contribution.<sup>*</sup>Corresponding author. (e-mail: zenglong@sz.tsinghua.edu.cn) Zhe Ni, Xiao-Xin Deng, Cong Tai, Xin-Yue Zhu, and Long Zeng are with Shenzhen International Graduate School, Tsinghua University, Shenzhen, China. Xiang Wu is with Shenzhen Phudu Technology Inc., Shenzhen, China. Yong-Jin Liu is with MOE Key Laboratory of Pervasive Computing, Department of Computer Science and Technology, Tsinghua University, Beijing, China.')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_pattern = re.compile(r'<br><br>(?=<sup>)|affiliation', re.DOTALL)\n",
    "author,affli = re.split(split_pattern, contributors,1)\n",
    "author,affli"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(['Zhe Ni<sup>dagger</sup>',\n  ', Xiao-Xin Deng<sup>dagger</sup>',\n  ', Cong Tai<sup>dagger</sup>',\n  ', Xin-Yue Zhu, Xiang Wu, Yong-Jin Liu, Long Zeng<sup>*</sup>'],\n ['Zhe Ni',\n  ', Xiao-Xin Deng',\n  ', Cong Tai',\n  ', Xin-Yue Zhu, Xiang Wu, Yong-Jin Liu, Long Zeng'],\n ['<sup>dagger</sup>Equal contribution.',\n  '<sup>*</sup>Corresponding author. (e-mail: zenglong@sz.tsinghua.edu.cn) Zhe Ni, Xiao-Xin Deng, Cong Tai, Xin-Yue Zhu, and Long Zeng are with Shenzhen International Graduate School, Tsinghua University, Shenzhen, China. Xiang Wu is with Shenzhen Phudu Technology Inc., Shenzhen, China. Yong-Jin Liu is with MOE Key Laboratory of Pervasive Computing, Department of Computer Science and Technology, Tsinghua University, Beijing, China.'])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_pattern = re.compile(r'([^<>]*?<sup>.*?</sup>)')\n",
    "author_pattern = re.compile(r'([^<>]*?)<sup>.*?</sup>')\n",
    "authors = re.findall(author_pattern, author)\n",
    "authors1 = re.findall(author1_pattern, author)\n",
    "affiliation_pattern = re.compile(r'(<sup>.*?</sup>.*?)(?=<sup>|\\n+|$)')\n",
    "affiliations = re.findall(affiliation_pattern, affli)\n",
    "authors,authors1,affiliations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-04 18:38:59 - ERROR - split_text.py:222 - article :None,Title not found, parser error\n"
     ]
    },
    {
     "data": {
      "text/plain": "(None, None)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = Article(text)\n",
    "article.authors,article.affiliations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "title:## I Introduction\n text:As the diffusion of partially-automated vehicles increases, there is an ever-growing interest in the estimation of the effects that higher-level automated vehicles (AV) will have on transportation systems in terms of efficiency, safety and emissions [1, 2, 3, 4, 5], with somewhat contrasting results in different contexts.\n\nMost existing studies analyzed the effect of AV diffusion by focusing only on automated longitudinal control of vehicles ([6, 7, 8]). Lane-changing behavior of AVs has received less interest, especially in urban scenarios. In particular, since in previous studies considering lane-changing behavior the simulated AVs were modeled both in terms of longitudinal control (with car-following models) and lateral control (with lane-changing models) ([9, 10, 11]), it was not possible to clearly isolate the specific impacts that AVs lane-changing behavior has on traffic.\n\nHere, a different approach to the problem is followed, and instead of modeling both longitudinal and lateral automated control at the same time, only the former is considered. This means that the simulated AVs in the present study follow an automated lane-changing behavior, while keeping a conventional car-following behavior. While it is of course not realistic to envisage the real-world production of vehicles that are automated exclusively in terms of lateral control, it allows us to isolate the effect of lane-changing behavior and to study its impact on network efficiency, which is the ultimate goal of the present study. To achieve it, several simulations were carried out using SUMO microsimulation software ([12, 13]), progressively increasing AV penetration rate, with lane-changing parameters chosen in accordance with existing literature studies that calibrated these parameters with real-world data (see Section II)."
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.groups[3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'chatcmpl-8aNkk1yfklX8XWH7l31zBX1chT16Q',\n 'object': 'chat.completion',\n 'created': 1703681806,\n 'model': 'gpt-3.5-turbo-1106',\n 'choices': [{'index': 0,\n   'message': {'role': 'assistant',\n    'content': '```markdown\\n| case | Fig. | on shortcut | on \\\\(\\\\mathcal{F}\\\\) | error (\\\\%) | remark |\\n|------|------|-------------|--------------------|------------|--------|\\n| original [1] | Fig. 2(a) | 1 | 1 | **6.61** |  |\\n| constant scaling | Fig. 2(b) | 0 | 1 | fail | This is a plain net |\\n|  |  | 0.5 | 1 | fail |  |\\n|  |  | 0.5 | 0.5 | 12.35 | frozen gating |\\n| exclusive gating | Fig. 2(c) | \\\\(1-g(\\\\mathbf{x})\\\\) | \\\\(g(\\\\mathbf{x})\\\\) | fail | init \\\\(b_{g}\\\\)=0 to \\\\(-5\\\\) |\\n|  |  | \\\\(1-g(\\\\mathbf{x})\\\\) | \\\\(g(\\\\mathbf{x})\\\\) | 8.70 | init \\\\(b_{g}\\\\)=-6 |\\n|  |  | \\\\(1-g(\\\\mathbf{x})\\\\) | \\\\(g(\\\\mathbf{x})\\\\) | 9.81 | init \\\\(b_{g}\\\\)=-7 |\\n| shortcut-only gating | Fig. 2(d) | \\\\(1-g(\\\\mathbf{x})\\\\) | 1 | 12.86 | init \\\\(b_{g}\\\\)=0 |\\n|  |  | \\\\(1-g(\\\\mathbf{x})\\\\) | 1 | 6.91 | init \\\\(b_{g}\\\\)=-6 |\\n| 1\\\\(\\times\\\\)1 conv shortcut | Fig. 2(e) | 1\\\\(\\times\\\\)1 conv | 1 | 12.22 |  |\\n| dropout shortcut | Fig. 2(f) | dropout 0.5 | 1 | fail |  |\\n```'},\n   'finish_reason': 'stop'}],\n 'usage': {'prompt_tokens': 564,\n  'completion_tokens': 391,\n  'total_tokens': 955},\n 'system_fingerprint': 'fp_772e8125bb'}"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "base_url = \"https://api.ai-gaochao.cn/v1\"\n",
    "url = base_url+\"/chat/completions\"\n",
    "api_key = \"sk-nRjm3MuSfJ9yoDZu987f9f8c0b014052B463046c0587B01c\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "}\n",
    "prompts_path = './prompts_config_zh.json'\n",
    "with open(prompts_path,'rb') as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "\n",
    "messages= [{\"role\": \"system\", \"content\": \"你是一个很有用的助手，擅长使用解决用户需求\"}]\n",
    "\n",
    "user_input = \"\"\"\\begin{table}\n",
    "\\begin{tabular}{c|c|c|c|c|c} \\hline case & Fig. & on shortcut & on \\(\\mathcal{F}\\) & error (\\%) & remark \\\\ \\hline \\hline original [1] & Fig. 2(a) & 1 & 1 & **6.61** & \\\\ \\hline \\multirow{3}{*}{\\begin{tabular}{c} constant \\\\ scaling \\\\ \\end{tabular} } & \\multirow{3}{*}{Fig. 2(b)} & 0 & 1 & fail & This is a plain net \\\\  & & 0.5 & 1 & fail & \\\\  & & 0.5 & 0.5 & 12.35 & frozen gating \\\\ \\hline \\multirow{3}{*}{\\begin{tabular}{c} exclusive \\\\ gating \\\\ \\end{tabular} } & \\multirow{3}{*}{Fig. 2(c)} & \\(1-g(\\mathbf{x})\\) & \\(g(\\mathbf{x})\\) & fail & init \\(b_{g}\\)=0 to \\(-5\\) \\\\  & & \\(1-g(\\mathbf{x})\\) & \\(g(\\mathbf{x})\\) & 8.70 & init \\(b_{g}\\)=-6 \\\\  & & \\(1-g(\\mathbf{x})\\) & \\(g(\\mathbf{x})\\) & 9.81 & init \\(b_{g}\\)=-7 \\\\ \\hline \\multirow{3}{*}{\n",
    "\\begin{tabular}{c} shortcut-only \\\\ gating \\\\ \\end{tabular} } & \\multirow{3}{*}{Fig. 2(d)} & \\(1-g(\\mathbf{x})\\) & 1 & 12.86 & init \\(b_{g}\\)=0 \\\\  & & \\(1-g(\\mathbf{x})\\) & 1 & 6.91 & init \\(b_{g}\\)=-6 \\\\ \\hline\n",
    "1\\(\\times\\)1 conv shortcut & Fig. 2(e) & 1\\(\\times\\)1 conv & 1 & 12.22 & \\\\ \\hline dropout shortcut & Fig. 2(f) & dropout 0.5 & 1 & fail & \\\\ \\hline \\end{tabular}\n",
    "\\end{table}\n",
    "\n",
    "将上述内容转换成标准形式的markdown表格\n",
    "\"\"\"\n",
    "messages.append({'role': 'user', 'content': user_input})\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"model\": \"gpt-3.5-turbo-1106\",\n",
    "    \"messages\": messages,\n",
    "    # \"response_format\": { \"type\": \"json_object\" },\n",
    "}\n",
    "raw_response = requests.post(url, headers=headers, json=parameters)\n",
    "response = json.loads(raw_response.content.decode(\"utf-8\"))\n",
    "response\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "'```markdown\\n| case | Fig. | on shortcut | on \\\\(\\\\mathcal{F}\\\\) | error (\\\\%) | remark |\\n|------|------|-------------|--------------------|------------|--------|\\n| original [1] | Fig. 2(a) | 1 | 1 | **6.61** |  |\\n| constant scaling | Fig. 2(b) | 0 | 1 | fail | This is a plain net |\\n|  |  | 0.5 | 1 | fail |  |\\n|  |  | 0.5 | 0.5 | 12.35 | frozen gating |\\n| exclusive gating | Fig. 2(c) | \\\\(1-g(\\\\mathbf{x})\\\\) | \\\\(g(\\\\mathbf{x})\\\\) | fail | init \\\\(b_{g}\\\\)=0 to \\\\(-5\\\\) |\\n|  |  | \\\\(1-g(\\\\mathbf{x})\\\\) | \\\\(g(\\\\mathbf{x})\\\\) | 8.70 | init \\\\(b_{g}\\\\)=-6 |\\n|  |  | \\\\(1-g(\\\\mathbf{x})\\\\) | \\\\(g(\\\\mathbf{x})\\\\) | 9.81 | init \\\\(b_{g}\\\\)=-7 |\\n| shortcut-only gating | Fig. 2(d) | \\\\(1-g(\\\\mathbf{x})\\\\) | 1 | 12.86 | init \\\\(b_{g}\\\\)=0 |\\n|  |  | \\\\(1-g(\\\\mathbf{x})\\\\) | 1 | 6.91 | init \\\\(b_{g}\\\\)=-6 |\\n| 1\\\\(\\times\\\\)1 conv shortcut | Fig. 2(e) | 1\\\\(\\times\\\\)1 conv | 1 | 12.22 |  |\\n| dropout shortcut | Fig. 2(f) | dropout 0.5 | 1 | fail |  |\\n```'"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = response[\"choices\"][0][\"message\"]['content']\n",
    "x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "file_path = \"./data/output.md\"\n",
    "y = re.search(\"```markdown(.*)```\", x, re.DOTALL)\n",
    "with open(file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(y.group(1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始 DataFrame:\n",
      "       precision  recall\n",
      "train       0.85    0.78\n",
      "test        0.92    0.95\n",
      "\n",
      "更新后的 DataFrame:\n",
      "       precision  recall\n",
      "train       0.85    0.78\n",
      "test        0.96    0.90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建一个示例 DataFrame\n",
    "data = {'precision': [0.85, 0.92],\n",
    "        'recall': [0.78, 0.95]}\n",
    "\n",
    "df = pd.DataFrame(data, index=['train', 'test'])\n",
    "print(\"初始 DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# 模拟一些新的评估结果\n",
    "eval_names = ['precision', 'recall']\n",
    "eval_type = 'test'\n",
    "eval_results = [0.96, 0.90]\n",
    "\n",
    "# 更新 DataFrame 中的特定位置\n",
    "for i in range(len(eval_names)):\n",
    "    df.loc[eval_type, eval_names[i]] = eval_results[i]\n",
    "\n",
    "print(\"\\n更新后的 DataFrame:\")\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取nougat解析好的原始文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92m<module>\u001B[0m:\u001B[94m19\u001B[0m                                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m16 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mreturn\u001B[0m full_text,full_path                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m17 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m18 \u001B[0mfull_text,file_names = test()                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m19 articles = [Article(i) \u001B[94mfor\u001B[0m i \u001B[95min\u001B[0m full_text]                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m20 \u001B[0marticles[\u001B[94m0\u001B[0m].authors                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m21 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92m<listcomp>\u001B[0m:\u001B[94m19\u001B[0m                                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m16 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mreturn\u001B[0m full_text,full_path                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m17 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m18 \u001B[0mfull_text,file_names = test()                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m19 articles = [Article(i) \u001B[94mfor\u001B[0m i \u001B[95min\u001B[0m full_text]                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m20 \u001B[0marticles[\u001B[94m0\u001B[0m].authors                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m21 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mNameError: \u001B[0mname \u001B[32m'Article'\u001B[0m is not defined\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> full_text,full_path                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span>full_text,file_names = test()                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>19 articles = [Article(i) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> full_text]                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 </span>articles[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].authors                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> full_text,full_path                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span>full_text,file_names = test()                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>19 articles = [Article(i) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> full_text]                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 </span>articles[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].authors                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'Article'</span> is not defined\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import re\n",
    "from submodule.openai_api import *\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "def test(show_num = 5):\n",
    "    raw_dir = './res/raw_mmd/'\n",
    "    file_list = os.listdir(raw_dir)\n",
    "    file_names = [i for i in file_list if i.endswith('.mmd') and '12' in i]\n",
    "    full_path = [Path(raw_dir)/i for i in file_names]\n",
    "    full_text = [i.read_text(encoding='utf-8') for i in full_path]\n",
    "    selected_inde =  random.choices(range(len(full_text)),k=show_num)\n",
    "    full_text,full_path = zip(*[(full_text[i],full_path[i]) for i in selected_inde])\n",
    "    return full_text,full_path\n",
    "\n",
    "full_text,file_names = test()\n",
    "articles = [Article(i) for i in full_text]\n",
    "articles[0].authors"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get institution and authors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author: \n",
      "Listwise Ranking in Large Language Models<br><br> Raphael Tang,<sup>1</sup> Xinyu Zhang<sup>*2</sup> Xueguang Ma<sup>2</sup> Jimmy Lin<sup>2</sup> Ferhan Ture<sup>1</sup>\n",
      " \n",
      "affiliations: : <sup>1</sup>Comcast Applied AI <sup>2</sup>University of Waterloo<br><br><sup>1</sup>{raphael_tang, ferhan_ture}@comcast.com <sup>2</sup>{x978zhang, x93ma, jimmylin}@uwaterloo.ca<br><br>Equal contribution.\n",
      "\n",
      "authors: ['Raphael Tang,<sup>1</sup>', 'Xinyu Zhang<sup>*2</sup>', 'Xueguang Ma<sup>2</sup>', 'Jimmy Lin<sup>2</sup>', 'Ferhan Ture<sup>1</sup>'] \n",
      "affiliations: ['<sup>1</sup>Comcast Applied AI ', '<sup>2</sup>University of Waterloo<br><br>', '<sup>1</sup>{raphael_tang, ferhan_ture}@comcast.com ', '<sup>2</sup>{x978zhang, x93ma, jimmylin}@uwaterloo.ca<br><br>Equal contribution.']\n"
     ]
    },
    {
     "data": {
      "text/plain": "(['Raphael Tang,<sup>1</sup>',\n  'Xinyu Zhang<sup>*2</sup>',\n  'Xueguang Ma<sup>2</sup>',\n  'Jimmy Lin<sup>2</sup>',\n  'Ferhan Ture<sup>1</sup>'],\n ['<sup>1</sup>Comcast Applied AI',\n  '<sup>2</sup>University of Waterloo<br><br>',\n  '<sup>1</sup>{raphael_tang, ferhan_ture}@comcast.com',\n  '<sup>2</sup>{x978zhang, x93ma, jimmylin}@uwaterloo.ca<br><br>Equal contribution.'],\n [Raphael Tang,<sup>1</sup>,\n  Xinyu Zhang<sup>*2</sup>,\n  Xueguang Ma<sup>2</sup>,\n  Jimmy Lin<sup>2</sup>,\n  Ferhan Ture<sup>1</sup>])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from typing import List,Union\n",
    "t = \"\"\"\n",
    "Listwise Ranking in Large Language Models<br><br> Raphael Tang,<sup>1</sup> Xinyu Zhang<sup>*2</sup> Xueguang Ma<sup>2</sup> Jimmy Lin<sup>2</sup> Ferhan Ture<sup>1</sup>\n",
    "affiliation: <sup>1</sup>Comcast Applied AI <sup>2</sup>University of Waterloo<br><br><sup>1</sup>{raphael_tang, ferhan_ture}@comcast.com <sup>2</sup>{x978zhang, x93ma, jimmylin}@uwaterloo.ca<br><br>Equal contribution.\n",
    "\"\"\"\n",
    "t2 = \"\"\"\n",
    "Haoyu Gao<sup>123</sup>+, Ting-En Lin<sup>2</sup>, Hangyu Li<sup>2</sup>, Min Yang<sup>3*</sup>,<br><br>**Yuchuan Wu<sup>2</sup>, Wentao Ma<sup>2</sup>, Yongbin Li<sup>2*</sup>**<br><br><sup>1</sup> University of Science and Technology of China <sup>2</sup> Alibaba Group<br><br><sup>3</sup>Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences<br><br>{hy.gao, min.yang}@siat.ac.cn<br><br>shuide.lyb@alibaba-inc.com<br><br>Corresponding authors.Work done while interning at Alibaba.\n",
    "\"\"\"\n",
    "def list_strip(l:List[str]):\n",
    "    return [i.strip() for i in l]\n",
    "\n",
    "def filter_with_NER(text:List[str],NER:str='ORG'):\n",
    "    assert NER in ['ORG','PERSON'],logging.error(f'NER must be ORG or PERSON, but got {NER}')\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    docs = [nlp(i) for i in text]\n",
    "    def filter_func(doc):\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ != NER:\n",
    "                return False\n",
    "        return True\n",
    "    return list(filter(filter_func,docs))\n",
    "\n",
    "split_pattern = re.compile(r'<br><br>(?=<sup>)|affiliation',re.DOTALL)\n",
    "author,affiliation = re.split(split_pattern,t,1)\n",
    "print('author:',author,'\\naffiliations:',affiliation)\n",
    "author_pattern = re.compile(r'([^<>]*?<sup>.*?</sup>)')\n",
    "authors = re.findall(author_pattern,author)\n",
    "affiliation_pattern = re.compile(r'(<sup>.*?</sup>.*?)(?=<sup>|\\n+|$)')\n",
    "affiliations = re.findall(affiliation_pattern,affiliation)\n",
    "authors = list_strip(authors)\n",
    "print('authors:',authors,'\\naffiliations:',affiliations)\n",
    "affiliations = list_strip(affiliations)\n",
    "authors,affiliations,filter_with_NER(authors,NER='PERSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs: [Haoyu Gao<sup>123</sup>, +, Ting-En Lin<sup>2</sup>, , Hangyu Li<sup>2</sup>, , Min Yang<sup>3*</sup>, ,<br><br>**Yuchuan Wu<sup>2</sup>, , Wentao Ma<sup>2</sup>, , Yongbin Li<sup>2*</sup>]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'+, Ting-En Lin<sup>2</sup>'"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_with_NER(text: List[str], NER: str = 'PERSON'):\n",
    "    assert NER in ['ORG', 'PERSON'], logging.error(f'NER must be ORG or PERSON, but got {NER}')\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    docs = [nlp(i) for i in text]\n",
    "    print('docs:',docs)\n",
    "    def filter_func(doc):\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ != NER:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    return list(filter(filter_func, docs))\n",
    "\n",
    "filter_with_NER(authors, NER='PERSON')[1].text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listwise Ranking 1 17 PERSON\n",
      "Large Language Models 21 42 WORK_OF_ART\n",
      "Raphael Tang,<sup>1</sup 51 75 PERSON\n",
      "Xinyu Zhang 77 88 PERSON\n",
      "Xueguang Ma 102 113 PERSON\n",
      "Jimmy Lin 126 135 PERSON\n",
      "x93ma 334 339 ORG\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "t1 = \"\"\"\n",
    "Haoyu Gao<sup>123</sup>+, Ting-En Lin<sup>2</sup>, Hangyu Li<sup>2</sup>, Min Yang<sup>3*</sup>,<br><br>**Yuchuan Wu<sup>2</sup>, Wentao Ma<sup>2</sup>, Yongbin Li<sup>2*</sup>**<br><br><sup>1</sup> University of Science and Technology of China <sup>2</sup> Alibaba Group<br><br><sup>3</sup>Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences<br><br>{hy.gao, min.yang}@siat.ac.cn<br><br>shuide.lyb@alibaba-inc.com<br><br>Corresponding authors.Work done while interning at Alibaba.\n",
    "\"\"\"\n",
    "doc = nlp(t)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text1 = 'loss (y-axis on the left).\\\\n\\\\n### Di\\nscussions\\\\n\\\\nAs indicated by the grey'\n",
    "\n",
    "\n",
    "pattern = re.compile(r'(#+.*?)(\\\\n+)',re.DOTALL)\n",
    "# pattern = re.compile('\\d*(\\\\n*)(.*)')\n",
    "\n",
    "print('text1:',text1)\n",
    "# print('text2:',text2)\n",
    "matches = re.match(pattern, text1)\n",
    "\n",
    "print(\"1匹配结果:\", matches)\n",
    "\n",
    "# matches2 = re.findall(pattern, text2)\n",
    "# print(\"2匹配结果:\", matches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = './res/raw_mmd/2309_08182.mmd'\n",
    "with open(text_path,'r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "title_pattern = re.compile(r'(#+\\s+.*?)\\n+(.*?)#+',re.DOTALL)\n",
    "title = re.match(title_pattern, text)\n",
    "print('title:',title)\n",
    "title.group(1),title.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitle_pattern = re.compile(r'\\n+(#+\\s+.*?)\\n+')\n",
    "subtitle = re.findall(subtitle_pattern, text)\n",
    "subtext = re.split(subtitle_pattern, text)\n",
    "subtitle = [i.strip() for i in subtitle if i.strip() != '']\n",
    "if 'abstract' in subtitle[0].lower():\n",
    "    subtitle[0] = subtitle[0].replace('######','##')\n",
    "\n",
    "subtitle"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NER判别作者与机构"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Smith PERSON\n",
      "XYZ University ORG\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# 加载spaCy的英文预训练模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 要分析的文本\n",
    "text = \"John Smith is a researcher at XYZ University.\"\n",
    "text2 = \"\"\"Boxin Wang<sup>1 &dagger;</sup>, Wei Ping<sup>1 &dagger;</sup>, Lawrence McAfee<sup>1</sup>, Peng Xu<sup>1</sup>, Bo Li<sup>2</sup>, Mohammad Shoeybi<sup>1</sup>, Bryan Catanzaro<sup>1</sup> <sup>1</sup> NVIDIA <sup>2</sup> University of Illinois at Urbana−Champaign <sup>&dagger;</sup>boxinw, wping@nvidia.com∗∗\"\"\"\n",
    "# 使用spaCy进行实体识别\n",
    "doc = nlp(text)\n",
    "\n",
    "# 输出识别的实体和它们的类型\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "author_pattern = re.compile(r'(?<={<)(.*?)(>})|(?<=<)(.*?)(<\\?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SPACE 库练手"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T01:45:48.524145Z",
     "start_time": "2023-10-10T01:45:48.484146400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy\n",
      "is\n",
      "an\n",
      "open\n",
      "-\n",
      "source\n",
      "software\n",
      "library\n",
      "for\n",
      "advanced\n",
      "NLP\n",
      "in\n",
      "Python\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# 加载英文的预训练语言模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 处理文本\n",
    "text = \"spaCy is an open-source software library for advanced NLP in Python.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# 打印文本的分词结果\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "token: running running\n",
      "run\n",
      "token: runs runs\n",
      "runner\n",
      "token: runner runner\n"
     ]
    }
   ],
   "source": [
    "# 获取单词的基本形式\n",
    "doc = nlp(\"running runs runner\")\n",
    "for token in doc:\n",
    "    print( token.lemma_)\n",
    "    print('token:',token,token.text)\n",
    "# 输出：running run runner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy INTJ\n",
      "is AUX\n",
      "a DET\n",
      "great ADJ\n",
      "tool NOUN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"spaCy is a great tool\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词结果:\n",
      "spaCy\n",
      "is\n",
      "an\n",
      "open\n",
      "-\n",
      "source\n",
      "software\n",
      "library\n",
      "for\n",
      "advanced\n",
      "NLP\n",
      "in\n",
      "Python\n",
      ".\n",
      "\n",
      "词性标签:\n",
      "spaCy INTJ\n",
      "is AUX\n",
      "an DET\n",
      "open ADJ\n",
      "- PUNCT\n",
      "source NOUN\n",
      "software NOUN\n",
      "library NOUN\n",
      "for ADP\n",
      "advanced ADJ\n",
      "NLP PROPN\n",
      "in ADP\n",
      "Python PROPN\n",
      ". PUNCT\n",
      "\n",
      "命名实体:\n",
      "NLP ORG\n",
      "Python GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# 加载英文的预训练语言模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 处理文本\n",
    "text = \"spaCy is an open-source software library for advanced NLP in Python.\"\n",
    "\n",
    "# 将文本传递给nlp管道进行处理\n",
    "doc = nlp(text)\n",
    "\n",
    "# 现在，doc对象包含了处理后的文本信息\n",
    "# 你可以访问各种属性，例如tokens, 词性标签, 命名实体等\n",
    "\n",
    "# 打印分词结果\n",
    "print(\"分词结果:\")\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "# 打印词性标签\n",
    "print(\"\\n词性标签:\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)\n",
    "\n",
    "# 打印命名实体\n",
    "print(\"\\n命名实体:\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 验证get_links"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submodule.arxiv_links import get_arxiv_links\n",
    "proxies = {'http': 'http://127.0.0.1:7890',\n",
    "       'https': 'http://127.0.0.1:7890', 'ftp': 'ftp://127.0.0.1:7890'}\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0\"}\n",
    "links,title,abs,authors = get_arxiv_links(key_word = None,proxies = proxies,headers=headers,max_num = 10,show_meta_data = True)\n",
    "\n",
    "for i,item in enumerate(zip(links,title,abs,authors)):\n",
    "    print('-'*20)\n",
    "    print('index:',i)\n",
    "    print('title:',item[1])\n",
    "    print('authors:',item[3])\n",
    "    print('link:',item[0])\n",
    "    print('abs:',repr(item[2]))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T01:41:38.965524500Z",
     "start_time": "2023-10-10T01:41:38.026278200Z"
    }
   },
   "outputs": [],
   "source": [
    "!jt -t chesterish -fs 95 -altp -tfs 11 -nfs 115 -cellw 88% -T -N -kl -cursw 5"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## retrying"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from retrying import retry\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "max_retry = 5\n",
    "wait_fixed = 1000\n",
    "\n",
    "@retry(stop_max_attempt_number=max_retry, wait_fixed=wait_fixed)\n",
    "def _get_response(url: str, proxies=None, header=None):\n",
    "    \"\"\"Get response.\"\"\"\n",
    "    logging.info(f'Getting response from {url}')\n",
    "    response = requests.get(url, proxies=proxies, headers=header)\n",
    "\n",
    "    return response\n",
    "url = \"https://www.example.com\"\n",
    "\n",
    "\n",
    "proxies = {'http': 'http://127.0.0.1:7890',\n",
    "           'https': 'http://127.0.0.1:7890', 'ftp': 'ftp://127.0.0.1:7890'}\n",
    "header = None\n",
    "\n",
    "try:\n",
    "    respon = _get_response(url,proxies = proxies,header = header)\n",
    "except Exception as e:\n",
    "    logging.error(f'All {max_retry} retries failed.')\n",
    "    raise e\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'#fkopsdfkp'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  re\n",
    "x = 'aspdjipadjipa#fkopsdfkp'\n",
    "pattern = re.compile('#+(.*)p')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T01:47:16.752879400Z",
     "start_time": "2023-10-10T01:47:16.678879800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration)\n",
    "#now a_function_requiring_decoration is wrapped by wrapTheFunction()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n'Mengkang Hu <sup>&spades;</sup>  Yao Mu <sup>&spades;</sup>  Xinmiao Yu<sup>&hearts;</sup>  Mingyu Ding<sup>&spades;</sup>  Shiguang Wu<sup>&hearts;</sup>',||$$~Authors:~Men\\ngkang~Hu,~~~Yao~Mu,~~~Xinmiao~Yu,~~~Mingyu~Ding,~~\\\\~Shiguang~Wu,~~~Wenqi~Shao,~~~Qiguang~Chen,~~~Bin~Wang,~~~Yu~Qiao,\\\\~~~Ping~Luo~$$,\\n parser_affiliations:**Wenqi Shao<sup>&spades;</sup>  Qiguang Chen<sup>&hearts;</sup>  Bin Wang<sup>&hearts;</sup>  Yu Qiao<sup>&spades;</sup>  Ping Luo<sup>&spades;</sup> <sup>&spades;</sup>**<sup>&spades;</sup>The Universi\\nty of Hong Kong <sup>&hearts;</sup>Harbin Institute of Technology<sup>&hearts;</sup>Noah's Ark Laboratory <sup>&spades;</sup>Shanghai AI LaboratoryCorresponding authors: Mingyu Ding and Ping Luo ({dingmyu\\n, pluo.lh}@gmail.com).\\n\""
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"\n",
    "'Mengkang Hu \\\\(\\\\spadesuit\\\\)  Yao Mu \\\\(\\\\spadesuit\\\\)  Xinmiao Yu\\\\(\\\\heartsuit\\\\)  Mingyu Ding\\\\(\\\\spadesuit\\\\)  Shiguang Wu\\\\(\\\\heartsuit\\\\)',||$$~Authors:~Men\n",
    "gkang~Hu,~~~Yao~Mu,~~~Xinmiao~Yu,~~~Mingyu~Ding,~~\\\\~Shiguang~Wu,~~~Wenqi~Shao,~~~Qiguang~Chen,~~~Bin~Wang,~~~Yu~Qiao,\\\\~~~Ping~Luo~$$,\n",
    " parser_affiliations:**Wenqi Shao\\(\\spadesuit\\)  Qiguang Chen\\(\\heartsuit\\)  Bin Wang\\(\\heartsuit\\)  Yu Qiao\\(\\spadesuit\\)  Ping Luo\\(\\spadesuit\\) \\(\\spadesuit\\)**\\(\\spadesuit\\)The Universi\n",
    "ty of Hong Kong \\(\\heartsuit\\)Harbin Institute of Technology\\(\\heartsuit\\)Noah's Ark Laboratory \\(\\spadesuit\\)Shanghai AI LaboratoryCorresponding authors: Mingyu Ding and Ping Luo ({dingmyu\n",
    ", pluo.lh}@gmail.com).\n",
    "\"\"\"\n",
    "\n",
    "def format_transfer( text):\n",
    "    format_dic = {\n",
    "        r'dagger': '&dagger;',\n",
    "        r'ddagger': '&ddagger;',\n",
    "        r'S': '&sect;',\n",
    "        r'P': '&para;',\n",
    "        r'clubsuit': '&clubs;',\n",
    "        r'diamondsuit': '&diams;',\n",
    "        r'heartsuit': '&hearts;',\n",
    "        r'spadesuit': '&spades;',\n",
    "        r'flat': '&flat;',\n",
    "        r'natural': '&natural;',\n",
    "        r'sharp': '&sharp;'\n",
    "    }\n",
    "\n",
    "    for key, value in format_dic.items():\n",
    "        pattern = re.compile(rf'\\\\\\(\\\\{key}\\\\\\)')\n",
    "        text = re.sub(pattern, f'<sup>{value}</sup>', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "text = format_transfer(text)\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T01:51:07.969804500Z",
     "start_time": "2023-10-10T01:51:07.953804300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "ProxyError",
     "evalue": "HTTPSConnectionPool(host='api.chatanywhere.cn', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None)))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionResetError\u001B[0m                      Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:700\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    699\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_new_proxy_conn \u001B[38;5;129;01mand\u001B[39;00m http_tunnel_required:\n\u001B[1;32m--> 700\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_proxy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:996\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._prepare_proxy\u001B[1;34m(self, conn)\u001B[0m\n\u001B[0;32m    994\u001B[0m     conn\u001B[38;5;241m.\u001B[39mtls_in_tls_required \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 996\u001B[0m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\urllib3\\connection.py:414\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    412\u001B[0m     context\u001B[38;5;241m.\u001B[39mload_default_certs()\n\u001B[1;32m--> 414\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[43mssl_wrap_socket\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeyfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcertfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcert_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    418\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_password\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_password\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_certs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_certs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    421\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[43m    \u001B[49m\u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    424\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtls_in_tls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtls_in_tls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    425\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;66;03m# If we're using all defaults and the connection\u001B[39;00m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001B[39;00m\n\u001B[0;32m    429\u001B[0m \u001B[38;5;66;03m# for the host.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001B[0m, in \u001B[0;36mssl_wrap_socket\u001B[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m send_sni:\n\u001B[1;32m--> 449\u001B[0m     ssl_sock \u001B[38;5;241m=\u001B[39m \u001B[43m_ssl_wrap_socket_impl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtls_in_tls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001B[0m, in \u001B[0;36m_ssl_wrap_socket_impl\u001B[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001B[0m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m server_hostname:\n\u001B[1;32m--> 493\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrap_socket\u001B[49m\u001B[43m(\u001B[49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\ssl.py:500\u001B[0m, in \u001B[0;36mSSLContext.wrap_socket\u001B[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001B[0m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrap_socket\u001B[39m(\u001B[38;5;28mself\u001B[39m, sock, server_side\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    495\u001B[0m                 do_handshake_on_connect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    496\u001B[0m                 suppress_ragged_eofs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    497\u001B[0m                 server_hostname\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, session\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    498\u001B[0m     \u001B[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001B[39;00m\n\u001B[0;32m    499\u001B[0m     \u001B[38;5;66;03m# ctx._wrap_socket()\u001B[39;00m\n\u001B[1;32m--> 500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msslsocket_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_side\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_side\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\ssl.py:1073\u001B[0m, in \u001B[0;36mSSLSocket._create\u001B[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001B[0m\n\u001B[0;32m   1072\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1073\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1074\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mOSError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\ssl.py:1342\u001B[0m, in \u001B[0;36mSSLSocket.do_handshake\u001B[1;34m(self, block)\u001B[0m\n\u001B[0;32m   1341\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msettimeout(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m-> 1342\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1343\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[1;31mConnectionResetError\u001B[0m: [WinError 10054] 远程主机强迫关闭了一个现有的连接。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\requests\\adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[1;32m--> 489\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[0;32m    503\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    785\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[1;32m--> 787\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    790\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001B[0m, in \u001B[0;36mRetry.increment\u001B[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_retry\u001B[38;5;241m.\u001B[39mis_exhausted():\n\u001B[1;32m--> 592\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause))\n\u001B[0;32m    594\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
      "\u001B[1;31mMaxRetryError\u001B[0m: HTTPSConnectionPool(host='api.chatanywhere.cn', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None)))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mProxyError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [16], line 34\u001B[0m\n\u001B[0;32m     23\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo-16k-0613\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: messages,\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m15000\u001B[39m,\n\u001B[0;32m     27\u001B[0m }\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# 构建请求体\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# data = {\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m#     'prompt': 'Hello, world!',\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m#     'max_tokens': 10,\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m#     'model': 'gpt-3.5-turbo-16k-0613',\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# }\u001B[39;00m\n\u001B[1;32m---> 34\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m response \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mcontent\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m     36\u001B[0m response\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\requests\\api.py:115\u001B[0m, in \u001B[0;36mpost\u001B[1;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[0;32m    105\u001B[0m \n\u001B[0;32m    106\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\requests\\sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    585\u001B[0m }\n\u001B[0;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\requests\\sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\requests\\adapters.py:559\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    556\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RetryError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, _ProxyError):\n\u001B[1;32m--> 559\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ProxyError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[0;32m    561\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, _SSLError):\n\u001B[0;32m    562\u001B[0m     \u001B[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001B[39;00m\n\u001B[0;32m    563\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SSLError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "\u001B[1;31mProxyError\u001B[0m: HTTPSConnectionPool(host='api.chatanywhere.cn', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None)))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "base_url = \"https://api.chatanywhere.cn/v1\"\n",
    "#base_url = \"https://api.openai.com/v1\"\n",
    "url = base_url + \"/chat/completions\"\n",
    "api_key = \"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\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "}\n",
    "\n",
    "proxies = {'http': 'http://127.0.0.1:7890',\n",
    "       'https': 'http://127.0.0.1:7890', 'ftp': 'ftp://127.0.0.1:7890'}\n",
    "system_prompt = \"you are a good helper\"\n",
    "messages = [{\n",
    "    'role': 'system', 'content': system_prompt\n",
    "}]\n",
    "messages.append({\n",
    "    'role': 'user', 'content': 'I want to know the weather in Beijing'\n",
    "})\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 15000,\n",
    "}\n",
    "# 构建请求体\n",
    "# data = {\n",
    "#     'prompt': 'Hello, world!',\n",
    "#     'max_tokens': 10,\n",
    "#     'model': 'gpt-3.5-turbo-16k-0613',\n",
    "# }\n",
    "response = requests.post(url, headers=headers, json=params,proxies = proxies)\n",
    "response = json.loads(response.content.decode(\"utf-8\"))\n",
    "response"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'D:\\\\Github\\\\code_arxiv_summarizer(local)\\\\code_arxiv_summarizer\\\\data'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('data')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "openai_info = {'prompts':'./prompts_config.json'}\n",
    "with open(openai_info['prompts'], 'r') as f:\n",
    "    openai_info['prompts'] = json.load(f)\n",
    "\n",
    "type(openai_info['prompts'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "['a1##', 'b2##', 'c3##']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['a','b','c']\n",
    "y = ['1','2','3']\n",
    "\n",
    "z = [i+j+'##' for i,j in zip(x,y)]\n",
    "z"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append path: D:\\Github\\code_arxiv_summarizer(local)\\code_arxiv_summarizer\\submodule\\nougat_main\\nougat\\dataset\n",
      "model: gpt-3.5-turbo,messages: [{'role': 'system', 'content': 'you are a good helper'}, {'role': 'user', 'content': 'I want to know the weather in Beijing'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": "27"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from submodule.openai_api import num_tokens_from_messages\n",
    "\n",
    "messages = [{\n",
    "    'role': 'system', 'content': 'you are a good helper'\n",
    "}]\n",
    "\n",
    "messages.append({\n",
    "    'role': 'user', 'content': 'I want to know the weather in Beijing'\n",
    "})\n",
    "\n",
    "num_tokens_from_messages(messages,model = 'gpt-3.5-turbo')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "({'http': 'http://127.0.0.1:7890',\n  'https': 'http://127.0.0.1:7890',\n  'ftp': 'ftp://127.0.0.1:7890',\n  'host': 'http://localhost:7890'},\n dict)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "yaml_path = './config.yaml'\n",
    "with open(yaml_path, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "config['arxiv']['proxy'],type(config['arxiv']['proxy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test chat func"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:split mode: group,start split text\n",
      "INFO:root:load token encode_model: cl100k_base\n",
      "ERROR:root:article :old_prom_2309_08532.mmd,Title not found, parser error\n",
      "INFO:root:finish split,grid:2,num_parts:6,max length of part:6062\n",
      "INFO:root:starting summary with openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:connect openai api through url:https://api.ai-gaochao.cn/v1, with 4 processes without rate limit\n",
      "100%|██████████| 6/6 [00:00<00:00, 8636.18it/s]\n",
      "INFO:root:load token encode_model: cl100k_base\n",
      "INFO:root:load token encode_model: cl100k_base\n",
      "INFO:root:load token encode_model: cl100k_base\n",
      "INFO:root:load token encode_model: cl100k_base\n",
      "INFO:root:load token encode_model: cl100k_base\n",
      "INFO:root:load token encode_model: cl100k_base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n",
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n",
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n",
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:summary with openai finished,starting resummry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_resp: ['\\n## abstract:\\n This paper focuses on processing-in-memory (PIM) systems, aiming to overcome the limitations of modern computing systems. Specifically, the study analyzes and demonstrates two non-stateful logic techniques - 1T1R logic and scouting logic - which can be integrated into a 1T1R memory array, similar to commercial RRAM products. The feasibility of using 1T1R SiO2 memristors for logic functions is investigated, and various logical functions are experimentally demonstrated, showing correct functionality in all cases. The paper also discusses the challenges and limitations of RRAM characteristics and the 1T1R configuration for logical functions. Overall, this research contributes to the understanding of PIM systems and their potential for improving computing performance. \\n\\n[Feedback content] The initial summary provides a concise overview of the primary objectives and research findings of the paper. However, it could be enhanced by incorporating more specific details such as the characterization parameters used for the 1T1R SiO2 memristors and the nature of the logical functions that were experimentally demonstrated. Additionally, the consequences of the discussed challenges and limitations should be highlighted to provide a comprehensive understanding of the research findings.', '\\n## intro:\\n', '\\n## experiment:\\n The experimental measurements conducted in this research utilized metal-insulator-metal (MIM) structures of VCM cells. These structures consisted of a TiN bottom electrode, SiO\\\\({}_{\\\\text{x}}\\\\) switching material, and a Ti top electrode. Ten different cells were examined to analyze cell-to-cell and cycle-to-cycle variability in the switching characteristics. The measurements were performed using a cascade summit12000 probe station controlled by a Keysight B1500A parameter analyzer. For the 1T1R logic, the input parameters were connected to various electrodes based on a defined array structure. The experiments involved 16 different input combinations to achieve the desired logic functions. Scouting logic experiments were also conducted, where resistive states of multiple memristors represented the inputs, and the output was determined by measuring the current through the memristors. The experimental setup and measurement parameters for both 1T1R and scouting logic were specified.', '\\n## result:\\n', '\\n## limit:\\n', \"\\n## conclusion:\\n\\nThis section concludes by demonstrating the successful computation capability of SiOx VCM cells in a 1T1R array. The cells accurately distinguish between the high resistance state (HRS; logical '0') and the low resistance state (LRS; logical '1'). Experimental investigation of two non-stateful logic types, a complete Boolean function with 1T1R array and scouting logic, revealed no logical failures for all critical cases in the Boolean set. The scouting logic effectively placed a reference current to distinguish between '0' and '1' for the logic functions AND, OR, and XOR. However, limitations were observed in the parallel connection of cells and differential voltage application. Future research should focus on addressing reliability issues of VCM devices to further explore the opportunities of this technology, ultimately enhancing efficiency in time and energy. The contributions of this section include validating the feasibility of computing with SiOx VCM cells and identifying areas for improvement.\"]\n",
      "resummary_prompt: You have been entrusted with the task of crafting a scholarly blog post summarizing a research paper in concise and readable manner. Follow this meticulous 3-step process 5 times:\\n\\n1. Generate the preliminary summary blog post, starting with the marker [preliminary blog content]. In preliminary content:\\n\\n- Briefly introduce the key ideas and goals of the paper using general descriptive terms.\\n\\n- Avoid in-depth technical details.\\n\\n- Keep it short and focused on main points.\\n\\n2. Provide constructive feedback to enhance the draft, starting with [Feedback content]. In feedback:\\n\\n- Clearly identify sections with redundant ideas that can be condensed.\\n\\n- Specify key technical details about methods, models, datasets, metrics etc. that need to be added. \\n\\n- Point out where numerical results or metrics can be used instead of generic statements.\\n\\n- Determine extraneous details and topics that can be removed or condensed.\\n\\n- Suggest improvements for clarity, concision and coherence in language and structure.\\n\\n- Flag any contradictions or misrepresentations of the paper's content.\\n\\n3. Generate the final summary blog incorporating feedback, starting with [final blog content]. In final content:\\n\\n- Synthesize key ideas into a coherent narrative flow.\\n\\n- Concisely include essence and details of each section.\\n\\n- Succinctly explain interconnections between sections.\\n\\n- Use formal yet simple academic language and style. \\n\\n- Maintain clarity, brevity, and coherence throughout.\\n\\nIn all sections, aim for high quality, concise and information-dense content.\n",
      "\n",
      " ```\n",
      "## abstract:\n",
      " This paper focuses on processing-in-memory (PIM) systems, aiming to overcome the limitations of modern computing systems. Specifically, the study analyzes and demonstrates two non-stateful logic techniques - 1T1R logic and scouting logic - which can be integrated into a 1T1R memory array, similar to commercial RRAM products. The feasibility of using 1T1R SiO2 memristors for logic functions is investigated, and various logical functions are experimentally demonstrated, showing correct functionality in all cases. The paper also discusses the challenges and limitations of RRAM characteristics and the 1T1R configuration for logical functions. Overall, this research contributes to the understanding of PIM systems and their potential for improving computing performance. \n",
      "\n",
      "[Feedback content] The initial summary provides a concise overview of the primary objectives and research findings of the paper. However, it could be enhanced by incorporating more specific details such as the characterization parameters used for the 1T1R SiO2 memristors and the nature of the logical functions that were experimentally demonstrated. Additionally, the consequences of the discussed challenges and limitations should be highlighted to provide a comprehensive understanding of the research findings.\n",
      "## intro:\n",
      "\n",
      "## experiment:\n",
      " The experimental measurements conducted in this research utilized metal-insulator-metal (MIM) structures of VCM cells. These structures consisted of a TiN bottom electrode, SiO\\({}_{\\text{x}}\\) switching material, and a Ti top electrode. Ten different cells were examined to analyze cell-to-cell and cycle-to-cycle variability in the switching characteristics. The measurements were performed using a cascade summit12000 probe station controlled by a Keysight B1500A parameter analyzer. For the 1T1R logic, the input parameters were connected to various electrodes based on a defined array structure. The experiments involved 16 different input combinations to achieve the desired logic functions. Scouting logic experiments were also conducted, where resistive states of multiple memristors represented the inputs, and the output was determined by measuring the current through the memristors. The experimental setup and measurement parameters for both 1T1R and scouting logic were specified.\n",
      "## result:\n",
      "\n",
      "## limit:\n",
      "\n",
      "## conclusion:\n",
      "\n",
      "This section concludes by demonstrating the successful computation capability of SiOx VCM cells in a 1T1R array. The cells accurately distinguish between the high resistance state (HRS; logical '0') and the low resistance state (LRS; logical '1'). Experimental investigation of two non-stateful logic types, a complete Boolean function with 1T1R array and scouting logic, revealed no logical failures for all critical cases in the Boolean set. The scouting logic effectively placed a reference current to distinguish between '0' and '1' for the logic functions AND, OR, and XOR. However, limitations were observed in the parallel connection of cells and differential voltage application. Future research should focus on addressing reliability issues of VCM devices to further explore the opportunities of this technology, ultimately enhancing efficiency in time and energy. The contributions of this section include validating the feasibility of computing with SiOx VCM cells and identifying areas for improvement.```\n",
      "score_prompt: ```summary result\n",
      "\n",
      "## abstract:\n",
      " This paper focuses on processing-in-memory (PIM) systems, aiming to overcome the limitations of modern computing systems. Specifically, the study analyzes and demonstrates two non-stateful logic techniques - 1T1R logic and scouting logic - which can be integrated into a 1T1R memory array, similar to commercial RRAM products. The feasibility of using 1T1R SiO2 memristors for logic functions is investigated, and various logical functions are experimentally demonstrated, showing correct functionality in all cases. The paper also discusses the challenges and limitations of RRAM characteristics and the 1T1R configuration for logical functions. Overall, this research contributes to the understanding of PIM systems and their potential for improving computing performance. \n",
      "\n",
      "[Feedback content] The initial summary provides a concise overview of the primary objectives and research findings of the paper. However, it could be enhanced by incorporating more specific details such as the characterization parameters used for the 1T1R SiO2 memristors and the nature of the logical functions that were experimentally demonstrated. Additionally, the consequences of the discussed challenges and limitations should be highlighted to provide a comprehensive understanding of the research findings.\n",
      "## intro:\n",
      "\n",
      "## experiment:\n",
      " The experimental measurements conducted in this research utilized metal-insulator-metal (MIM) structures of VCM cells. These structures consisted of a TiN bottom electrode, SiO\\({}_{\\text{x}}\\) switching material, and a Ti top electrode. Ten different cells were examined to analyze cell-to-cell and cycle-to-cycle variability in the switching characteristics. The measurements were performed using a cascade summit12000 probe station controlled by a Keysight B1500A parameter analyzer. For the 1T1R logic, the input parameters were connected to various electrodes based on a defined array structure. The experiments involved 16 different input combinations to achieve the desired logic functions. Scouting logic experiments were also conducted, where resistive states of multiple memristors represented the inputs, and the output was determined by measuring the current through the memristors. The experimental setup and measurement parameters for both 1T1R and scouting logic were specified.\n",
      "## result:\n",
      "\n",
      "## limit:\n",
      "\n",
      "## conclusion:\n",
      "\n",
      "This section concludes by demonstrating the successful computation capability of SiOx VCM cells in a 1T1R array. The cells accurately distinguish between the high resistance state (HRS; logical '0') and the low resistance state (LRS; logical '1'). Experimental investigation of two non-stateful logic types, a complete Boolean function with 1T1R array and scouting logic, revealed no logical failures for all critical cases in the Boolean set. The scouting logic effectively placed a reference current to distinguish between '0' and '1' for the logic functions AND, OR, and XOR. However, limitations were observed in the parallel connection of cells and differential voltage application. Future research should focus on addressing reliability issues of VCM devices to further explore the opportunities of this technology, ultimately enhancing efficiency in time and energy. The contributions of this section include validating the feasibility of computing with SiOx VCM cells and identifying areas for improvement.\n",
      "```\n",
      "\n",
      "Upon presenting the summary (delineated between the marker ```summary result``` e.g. ```summary result\\n [summary content]\\n```), execute an exhaustive appraisal of the paper employing stringent academic criteria:\\n\\n- Lucidity of Objectives and Central Theme: \\n\\n  - Quantification:  \\n  - Rationale:\\n\\n- Appositeness and Precision of Methodologies:\\n\\n  - Quantification:\\n  - Rationale:  \\n\\n- Veracity and Exactitude of Data and Findings:\\n\\n  - Quantification: \\n  - Rationale:\\n\\n- Depth of Analysis and Conclusiveness:\\n\\n  - Quantification:\\n  - Rationale:\\n    \\n- Overall Composition Quality:  \\n\\n  - Quantification:\\n  - Rationale:\\n\\n- Aggregate Score:\\n\\nFor each parameter, designate a score from 1 to 10, with 1 representing substandard and 10 exemplary excellence. Derive an overall assessment by calculating the average score.  \\n\\n**Supplemental Criteria Descriptors:**  \\n\\n- Lucidity of Objectives and Central Theme: Evaluate clarity of primary research objectives and central subject.\\n\\n- Appositeness and Precision of Methodologies: Assess suitability and elaboration of utilized systematic approaches. \\n\\n- Veracity and Exactitude of Data and Findings: Scrutinize accuracy and precision of presented information.\\n\\n- Depth of Analysis and Conclusiveness: Analyze insightfulness and cogency of deductions.\\n\\n- Overall Composition Quality: Evaluate grammar, orthography, syntax, semantics, and lucidity **(Note: Due to the given summary result potentially not fully exhibiting genuine composition quality, evaluate the subsequent original paper excerpt (enclosed between ```original paper excerpt``` e.g. ```original paper excerpt\\n[excerpt content]\\n```)** for overall composition quality).\n",
      "\n",
      "```\n",
      "original paper excerpt\n",
      "## AbstractProcessing-in-memory (PIM) is attractive to overcome the limitations of modern computing systems. Numerous PIM systems exist, varying by the technologies and logic techniques used. Successful operation of specific logic functions is crucial for effective processing-in-memory. Memristive non-stateful logic techniques are compatible with CMOS logic and can be integrated into a 1T1R memory array, similar to commercial RRAM products. This paper analyzes and demonstrates two non-stateful logic techniques: 1T1R logic and scouting logic. As a first step, the used 1T1R SiO2, valence change mechanism memristors are characterized in reference to their feasibility to perform logic functions. Various logical functions of the two logic techniques are experimentally demonstrated, showing correct functionality in all cases. Following the results, the challenges and limitations of the RRAM characteristics and 1T1R configuration for the application in logical functions are discussed.\n",
      "\n",
      " 1T1R Logic, Non-Stateful Logic, Scouting Logic, Experimental Demonstration, Reliability Issues\n",
      "## V ConclusionThis brief successfully demonstrated computing by SiOx VCM cells in a 1T1R array. The cells can distinguish between the high resistance state (HRS; logical '0') and the low resistance state (LRS; logical '1'). Two non-stateful logic types, a complete Boolean function with 1T1R array and scouting logic, have been experimentally investigated. All critical cases in the Boolean set with 1T1R array have been successfully operated without logical failures. Furthermore, the scouting logic had sufficient room for placing a reference current to distinguish between '0' and '1' for the logic functions AND, OR, and XOR. The limitations of the 1T1R array are evident in the parallel connection of cells and applying different voltages at each cell. Additionally, reliability issues of VCM devices still need to be investigated.\n",
      "\n",
      "With further research and development, the opportunities of this technology can be further explored, ultimately leading to greater efficiency in time and energy.\n",
      "```\n",
      "selected titles: ## Abstract ## V Conclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:connect openai api through url:https://api.ai-gaochao.cn/v1, with 4 processes without rate limit\n",
      "100%|██████████| 2/2 [00:00<00:00, 8551.08it/s]\n",
      "INFO:root:load token encode_model: cl100k_base\n",
      "INFO:root:load token encode_model: cl100k_base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n",
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n",
      "iteration re_respnse: [\"[preliminary blog content] \\nThis research paper explores processing-in-memory (PIM) systems, which aim to address the limitations of modern computing systems. The study focuses on two non-stateful logic techniques - 1T1R logic and scouting logic - that can be integrated into a 1T1R memory array similar to commercial RRAM products. The paper investigates the feasibility of using 1T1R SiO2 memristors for logic functions and demonstrates various logical functions experimentally, showing correct functionality in all cases. The research also discusses the challenges and limitations of RRAM characteristics and the 1T1R configuration for logical functions. Overall, this research contributes to the understanding of PIM systems and their potential for improving computing performance.\\n\\n[Feedback content]\\nThe preliminary summary provides a good starting point, but it could benefit from incorporating specific details such as the characterization parameters used for the 1T1R SiO2 memristors and the nature of the logical functions that were experimentally demonstrated. Additionally, the consequences of the discussed challenges and limitations should be highlighted to provide a comprehensive understanding of the research findings.\\n\\n[final blog content]\\nThis research paper delves into the realm of processing-in-memory (PIM) systems and their potential as a solution to the limitations of modern computing systems. By focusing on two non-stateful logic techniques - 1T1R logic and scouting logic - the study investigates the feasibility of using 1T1R SiO2 memristors integrated into a 1T1R memory array, similar to commercial RRAM products. These memristors serve as a medium for logic functions, and their capabilities are experimentally demonstrated, exhibiting correct functionality across various logical functions.\\n\\nThe experimental measurements are conducted on metal-insulator-metal (MIM) structures of VCM cells, comprising a TiN bottom electrode, SiOx switching material, and a Ti top electrode. To analyze the variability in the switching characteristics, ten different cells are examined, considering factors like cell-to-cell and cycle-to-cycle behavior. The measurements are carried out with a cascade summit12000 probe station controlled by a Keysight B1500A parameter analyzer.\\n\\nIn terms of logic implementation, the 1T1R logic involves connecting input parameters to electrodes according to a defined array structure. The experiments encompass 16 different input combinations to achieve the desired logic functions. Additionally, scouting logic experiments are conducted, wherein the resistive states of multiple memristors represent the inputs, and the output is determined by measuring the current through the memristors. The experimental setup and measurement parameters for both the 1T1R logic and scouting logic are clearly specified.\\n\\nThe results of the experiments demonstrate the successful computation capability of SiOx VCM cells in a 1T1R array. The cells accurately distinguish between high resistance state (HRS) and low resistance state (LRS), which correspond to logical '0' and '1', respectively. The investigation of the two non-stateful logic techniques, employing a complete Boolean function with 1T1R array and scouting logic, showcases the absence of logical failures for all critical cases in the Boolean set. The scouting logic effectively utilizes a reference current to differentiate between '0' and '1' for logic functions such as AND, OR, and XOR.\\n\\nHowever, limitations are observed in the parallel connection of cells and differential voltage application. These findings emphasize the need for future research to address the reliability issues of VCM devices, thereby unlocking the full potential of this technology and further enhancing efficiency in terms of time and energy consumption. Ultimately, this research validates the feasibility of computing with SiOx VCM cells and identifies areas for further improvement.\\n\\nIn conclusion, this research paper sheds light on the exciting possibilities of processing-in-memory (PIM) systems. By exploring the integration of 1T1R SiO2 memristors into a 1T1R memory array, the study demonstrates the potential of these systems to overcome the limitations of modern computing. Through experimental verification of non-stateful logic techniques, the research contributes to the understanding of PIM systems and paves the way for future advancements in computing performance.\", 'Analysis:\\n\\n- Lucidity of Objectives and Central Theme: 8/10\\nThe central theme of the paper, which is to investigate the feasibility of using 1T1R SiO2 memristors for logic functions in PIM systems, is clear. However, the objectives could have been more explicitly stated.\\n\\n- Appositeness and Precision of Methodologies: 9/10\\nThe methodologies used, such as the characterization of 1T1R SiO2 memristors and the experimental demonstration of logical functions using 1T1R logic and scouting logic, are appropriate for achieving the research objectives. The experimental setups and measurement parameters are specified, providing clarity.\\n\\n- Veracity and Exactitude of Data and Findings: 9/10\\nThe findings presented in the paper demonstrate correct functionality of the logical functions in all cases. The experimental measurements are conducted using appropriate techniques, and the data is accurately represented.\\n\\n- Depth of Analysis and Conclusiveness: 8/10\\nThe paper provides a comprehensive analysis of the logical functions achieved using 1T1R logic and scouting logic. The limitations and challenges of RRAM characteristics and the 1T1R configuration are discussed. However, the analysis could have delved deeper into the implications and consequences of these limitations.\\n\\n- Overall Composition Quality: 7/10\\nThe composition quality of the summary is satisfactory, with clear organization and coherence. However, there are some grammar and syntax errors that affect the readability. The original paper excerpt is not provided, so the overall composition quality cannot be fully evaluated.\\n\\n- Aggregate Score: 8.2/10\\n\\nOverall, the paper is well-structured and presents clear objectives, methodologies, data, and findings. The analysis and conclusions could have been more in-depth, and there are some issues with the composition quality.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:connect openai api through url:https://api.ai-gaochao.cn/v1, with 4 processes without rate limit\n",
      "100%|██████████| 2/2 [00:00<00:00, 26051.58it/s]\n",
      "INFO:root:load token encode_model: cl100k_base\n",
      "INFO:root:load token encode_model: cl100k_base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n",
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n",
      "iteration re_respnse: [\"[preliminary blog content] \\nThis paper explores the potential of processing-in-memory (PIM) systems to overcome the limitations of contemporary computing systems. It specifically investigates the integration of two non-stateful logic techniques, 1T1R logic and scouting logic, into a 1T1R memory array using SiO2 memristors. The study demonstrates the correct functionality of various logical functions using these techniques. The research also discusses the challenges and limitations associated with RRAM characteristics and the 1T1R configuration for logical functions. Overall, this study contributes to our understanding of PIM systems and their potential for enhancing computing performance.\\n\\n[Feedback content]\\nThe initial summary provides a concise overview of the paper's objectives and findings. However, it can be improved by incorporating specific details, such as the characterization parameters used for the 1T1R SiO2 memristors and the nature of the logical functions that were experimentally demonstrated. Additionally, highlighting the consequences of the discussed challenges and limitations would provide a more comprehensive understanding of the research findings.\\n\\n[final blog content]\\nThis paper investigates the potential of processing-in-memory (PIM) systems by analyzing the integration of 1T1R logic and scouting logic techniques into a 1T1R memory array using SiO2 memristors. The study experimentally demonstrates the correct functionality of various logical functions achieved through these techniques. To conduct the experiments, metal-insulator-metal (MIM) structures of VCM cells were employed, utilizing TiN bottom electrodes, SiOx switching material, and Ti top electrodes. The measurements were performed using a cascade summit12000 probe station controlled by a Keysight B1500A parameter analyzer. The 1T1R logic experiments involved connecting input parameters to various electrodes based on a defined array structure, with 16 different input combinations tested. In scouting logic experiments, resistive states of multiple memristors represented the inputs, and the output was determined by measuring the current through the memristors. The experimental setup and measurement parameters for both 1T1R and scouting logic were specified.\\n\\nThe results of the experiments demonstrated that SiOx VCM cells in a 1T1R array accurately distinguished between the high resistance state (HRS; logical '0') and the low resistance state (LRS; logical '1'). The study also revealed no logical failures for all critical cases in the Boolean set when applying the two non-stateful logic techniques. The scouting logic effectively placed a reference current to distinguish between '0' and '1' for the logic functions AND, OR, and XOR. However, limitations were observed in the parallel connection of cells and the application of differential voltage.\\n\\nIn conclusion, this research validates the feasibility of computing with SiOx VCM cells in a 1T1R array and identifies areas for improvement. It contributes to the understanding of processing-in-memory (PIM) systems and their potential for enhancing computing performance. Future research should focus on addressing the reliability issues of VCM devices to further explore the opportunities of this technology, ultimately enhancing efficiency in time and energy.\", 'Upon analyzing the given summary, the following assessment can be made based on the provided criteria:\\n\\n- Lucidity of Objectives and Central Theme: 8\\n  - Quantification: The objectives and central theme of the paper are clear.\\n  - Rationale: The objectives are aligned with the central theme of exploring the feasibility and potential of processing-in-memory (PIM) systems.\\n\\n- Appositeness and Precision of Methodologies: 9\\n  - Quantification: The experimental methodologies are well-described.\\n  - Rationale: The chosen methodologies are appropriate for investigating the feasibility of 1T1R SiO2 memristors for logical functions and demonstrating the two non-stateful logic techniques.\\n\\n- Veracity and Exactitude of Data and Findings: 7\\n  - Quantification: The data and findings are presented, but specific details about the characterization parameters used for the 1T1R SiO2 memristors and the nature of the logical functions are missing.\\n  - Rationale: The paper lacks specific details and quantified results to fully assess the veracity and exactitude of the data and findings.\\n\\n- Depth of Analysis and Conclusiveness: 7\\n  - Quantification: The analysis lacks in-depth exploration of the challenges and limitations of RRAM characteristics and the 1T1R configuration for logical functions.\\n  - Rationale: The paper discusses the challenges and limitations but does not provide a comprehensive analysis or conclusive insights.\\n\\n- Overall Composition Quality: 6\\n  - Quantification: The composition quality is average with some minor flaws in grammar, orthography, and syntax.\\n  - Rationale: The summary does not exhibit exemplary composition quality, which may impact the overall readability and understanding.\\n\\n- Aggregate Score: (8+9+7+7+6)/5 = 7.4\\n\\nBased on the given criteria, the overall assessment score for the paper is 7.4.\\n\\nIt is important to note that the given summary result may not fully exhibit genuine composition quality. Therefore, further evaluation should be conducted using the original paper excerpt for a more accurate assessment.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:connect openai api through url:https://api.ai-gaochao.cn/v1, with 4 processes without rate limit\n",
      "100%|██████████| 2/2 [00:00<00:00, 21290.88it/s]\n",
      "INFO:root:load token encode_model: cl100k_base\n",
      "INFO:root:load token encode_model: cl100k_base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n",
      "append path: /Users/ke/workshop/code_pytorch/code_arxiv_summarizer/submodule/nougat_main/nougat/dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finished resummry the article,with the titles:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration re_respnse: [\"[preliminary blog content] This research paper explores the concept of processing-in-memory (PIM) systems and their potential to overcome the limitations of modern computing systems. Specifically, the study focuses on two non-stateful logic techniques - 1T1R logic and scouting logic - which can be integrated into a 1T1R memory array, similar to commercial RRAM products. The researchers investigate the feasibility of using 1T1R SiO2 memristors for logic functions and experimentally demonstrate various logical functions with correct functionality. The paper also discusses the challenges and limitations of RRAM characteristics and the 1T1R configuration for logical functions. Overall, this research contributes to the understanding of PIM systems and their potential for improving computing performance.\\n\\n[Feedback content] The initial summary does a good job of summarizing the main objectives and findings of the paper. However, it could be further improved by including more specific details about the characterization parameters used for the 1T1R SiO2 memristors and the nature of the logical functions that were experimentally demonstrated. Additionally, emphasizing the consequences of the discussed challenges and limitations would enhance the comprehensiveness of the summary.\\n\\n[final blog content] This research paper delves into the realm of processing-in-memory (PIM) systems, which hold immense promise for overcoming the limitations of contemporary computing systems. The focus of the study lies on two non-stateful logic techniques, namely 1T1R logic and scouting logic, which can be seamlessly integrated into a 1T1R memory array, akin to commercial RRAM products. By investigating the feasibility of employing 1T1R SiO2 memristors for logic functions, the researchers successfully demonstrate a range of logical functions with flawless functionality. These outcomes shed light on the potential of PIM systems in revolutionizing computing performance.\\n\\nThe experimental aspect of the research entails the utilization of metal-insulator-metal (MIM) structures comprised of VCM cells. The structure of these MIM structures encompasses a TiN bottom electrode, SiO\\\\({}_{\\\\text{x}}\\\\) switching material, and a Ti top electrode. The researchers meticulously analyze ten different cells to unravel the variability in both cell-to-cell and cycle-to-cycle switching characteristics. To perform these measurements, a cascade summit12000 probe station under the control of a Keysight B1500A parameter analyzer is employed. The experimental setup for the 1T1R logic involves connecting the input parameters to various electrodes based on a pre-defined array structure. By conducting experiments with 16 different input combinations, the desired logic functions are achieved. Additionally, scouting logic experiments are carried out, with the resistive states of multiple memristors representing the inputs and the output being determined by measuring the current through these memristors. The specifics of the experimental setup and measurement parameters for both 1T1R logic and scouting logic are meticulously outlined.\\n\\nWhile the experimental results showcase the successful computation capability of SiOx VCM cells in a 1T1R array, distinguishing between the high resistance state (HRS) representing logical '0' and the low resistance state (LRS) representing logical '1', limitations are uncovered in the parallel connection of cells and the application of differential voltage. However, the investigation of two non-stateful logic types, complete Boolean function with 1T1R array and scouting logic, reveals no logical failures in all critical cases within the Boolean set. The scouting logic effectively places a reference current to differentiate between '0' and '1' for the logic functions AND, OR, and XOR. In conclusion, this research validates the practicality of computing with SiOx VCM cells and highlights areas for improvement. Future endeavors should prioritize addressing the reliability issues of VCM devices to further exploit the potential of this technology, ultimately enhancing efficiency in terms of time and energy.\", 'Upon analyzing the summary, the paper titled \"Processing-In-Memory: Memristive Non-Stateful Logic Techniques\" focuses on processing-in-memory (PIM) systems and the utilization of non-stateful logic techniques to overcome the limitations of modern computing systems. The study assesses the feasibility of using 1T1R SiO2 memristors for logic functions and demonstrates various logical functions experimentally. The paper also addresses the challenges and limitations of RRAM characteristics and the 1T1R configuration for logical functions. Overall, this research contributes to the understanding of PIM systems and their potential for enhancing computing performance.\\n\\nNow, let\\'s evaluate the paper based on several academic criteria:\\n\\n- Lucidity of Objectives and Central Theme: The objectives and central theme of the paper are clearly stated. The primary objective is to investigate the feasibility of using 1T1R SiO2 memristors for logic functions and demonstrate various logical functions experimentally. The central theme revolves around the potential of PIM systems in improving computing performance.\\n\\n  - Quantification: 9\\n  - Rationale: 9\\n\\n- Appositeness and Precision of Methodologies: The methodologies employed, such as utilizing metal-insulator-metal (MIM) structures of VCM cells and conducting experiments on 1T1R logic and scouting logic, are relevant and precise.\\n\\n  - Quantification: 8\\n  - Rationale: 8\\n\\n- Veracity and Exactitude of Data and Findings: The data and findings presented are accurate and precise. The experimental measurements using the metal-insulator-metal (MIM) structures of VCM cells show correct functionality in all cases for the logical functions.\\n\\n  - Quantification: 9\\n  - Rationale: 9\\n\\n- Depth of Analysis and Conclusiveness: The analysis provided is insightful, discussing the challenges and limitations of RRAM characteristics and the 1T1R configuration for logical functions. The conclusions drawn from the experiments demonstrate the successful computation capability of the SiOx VCM cells in a 1T1R array.\\n\\n  - Quantification: 8\\n  - Rationale: 8\\n\\n- Overall Composition Quality: The composition quality of the summary is not explicitly provided, but the grammar, orthography, syntax, and semantics appear to be well-structured.\\n\\n  - Quantification: 7\\n  - Rationale: 7\\n\\n- Aggregate Score: The overall score is calculated by averaging the individual scores for each parameter.\\n\\n  - Aggregate Score: 8.2\\n\\nConsidering the given summary, the overall assessment indicates that the paper is academically rigorous, providing clear objectives, relevant methodologies, accurate data and findings, in-depth analysis, and acceptable composition quality.\\n\\n**Supplemental Criteria Descriptors:**\\n\\n- Lucidity of Objectives and Central Theme: The objectives and central theme are clearly stated and aligned with the research.\\n\\n- Appositeness and Precision of Methodologies: The methodologies are appropriate for the research objectives and are described with sufficient detail.\\n\\n- Veracity and Exactitude of Data and Findings: The data and findings are reliable and precise, supporting the research objectives.\\n\\n- Depth of Analysis and Conclusiveness: The analysis is comprehensive, and the conclusions are drawn based on the experimental results and discussions.\\n\\n- Overall Composition Quality: Although the summary does not explicitly exhibit composition quality, the language and structure appear to be acceptable.\\n\\nTo provide a more accurate assessment, the full paper would need to be thoroughly reviewed for a comprehensive evaluation of all academic criteria.']\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "from submodule.openai_api import  *\n",
    "from submodule.nougat_main import  nougat_predict\n",
    "from submodule.arxiv_links import get_arxiv_links\n",
    "from submodule.my_utils import *\n",
    "import re\n",
    "import time\n",
    "from logging.config import fileConfig\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import  requests\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# params = {\n",
    "#     \"openai_info\": openai_info,\n",
    "#     \"proxy\": {'http': 'http://127.0.0.1:7890',\n",
    "#               'https': 'http://127.0.0.1:7890',\n",
    "#               'ftp': 'ftp://127.0.0.1:7890'},\n",
    "#     \"artile_text\": 'djsaiodj',\n",
    "#     \"file_name\": 'test.mmd',\n",
    "#     \"gpt_config\": None\n",
    "# }\n",
    "#\n",
    "# print('params:',params)\n",
    "# url = 'http://127.0.0.1:8000/get_summaries/'\n",
    "# response = requests.post(url=url, json=params)\n",
    "# print('status_code:',response.status_code)\n",
    "# print('text:',response.text)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # logging_path = 'logging.ini'\n",
    "    # logging.config.fileConfig(logging_path)\n",
    "    # logger = logging.getLogger('applog')\n",
    "\n",
    "    yaml_path = './config.yaml'\n",
    "    with open(yaml_path, 'r') as config_file:\n",
    "        config = yaml.safe_load(config_file)\n",
    "    openai_info = config[\"openai\"]\n",
    "    with open(openai_info['prompts_path'], 'r') as f:\n",
    "        prompts = json.load(f)\n",
    "    arxiv_info = config['arxiv']\n",
    "    nougat_info = config[\"nougat\"]\n",
    "    proxy = arxiv_info['proxy']\n",
    "    ignore_titles = openai_info['ignore_title']\n",
    "    per_min =  3 if openai_info['rate_limit'] else None\n",
    "    md_path = './res/raw_mmd/2310_16843.mmd'\n",
    "    with open(md_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    # text = \"sdadasdasd\"\n",
    "    base_url = openai_info['base_url']\n",
    "    grid = 2\n",
    "    summerizer = OpenAI_Summarizer(openai_info, proxy, summary_prompts=prompts['section summary'],\n",
    "                                   resummry_prompts=prompts[\"blog summary\"], ignore_titles=ignore_titles,\n",
    "                                   acquire_mode='url',num_processes=4,base_url=base_url,requests_per_minute=per_min)\n",
    "    nowtime = time.time()\n",
    "    filename = 'old_prom_2309_08532.mmd'\n",
    "\n",
    "    titles, authors, affiliations, total_resp, re_respnse = summerizer.summary_with_openai(text,\n",
    "                                                                                          file_name=filename,\n",
    "                                                                                          init_grid=grid)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (4251774270.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[10], line 29\u001B[1;36m\u001B[0m\n\u001B[1;33m    return *x\u001B[0m\n\u001B[1;37m           ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "from submodule.openai_api import  *\n",
    "import re\n",
    "def clean_resp(raw_text_list):\n",
    "    \"\"\"\n",
    "    remove the special marker in head of response or the tail of response\n",
    "    Args:\n",
    "        raw_text_list: list of raw response\n",
    "\n",
    "    Returns: list of cleaned response\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(raw_text_list, str):\n",
    "        raw_text_list = [raw_text_list]\n",
    "    if not isinstance(raw_text_list, list):\n",
    "        raise ValueError(f'raw_text_list should be list or str, but got {type(raw_text_list)}')\n",
    "\n",
    "    cleaned_str_list = []\n",
    "    for raw_text in raw_text_list:\n",
    "        cleaned_str = re.sub(r'^[^a-zA-Z]*', '', raw_text)\n",
    "        cleaned_str = re.sub(r'[^a-zA-Z.]*$', '', cleaned_str)\n",
    "        cleaned_str_list.append(cleaned_str)\n",
    "    return cleaned_str_list\n",
    "\n",
    "raw_text_list = [\"djsaiodj\"]\n",
    "def f(x):\n",
    "    print('x:',x)\n",
    "    return *x\n",
    "\n",
    "y = f(raw_text_list)\n",
    "y\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件保存路径：1701596004659.mp3\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import uuid\n",
    "import requests\n",
    "import hashlib\n",
    "import time\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "YOUDAO_URL = 'https://openapi.youdao.com/ttsapi'\n",
    "APP_KEY = '21a52d8cbabd6256'\n",
    "APP_SECRET = 'MYttHedJuswCG6CNoyhd5YWH5egzQPSa'\n",
    "\n",
    "\n",
    "def encrypt(signStr):\n",
    "    \"\"\"对字符串进行MD5加密\"\"\"\n",
    "    hash_algorithm = hashlib.md5()\n",
    "    hash_algorithm.update(signStr.encode('utf-8'))\n",
    "    return hash_algorithm.hexdigest()\n",
    "\n",
    "\n",
    "def truncate(q):\n",
    "    \"\"\"将文本进行截断，保留前10个字符、后10个字符和长度信息\"\"\"\n",
    "    if q is None:\n",
    "        return None\n",
    "    size = len(q)\n",
    "    return q if size <= 20 else q[0:10] + str(size) + q[size - 10:size]\n",
    "\n",
    "\n",
    "def do_request(data):\n",
    "    \"\"\"发送POST请求到有道云API并返回响应\"\"\"\n",
    "    headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "    return requests.post(YOUDAO_URL, data=data, headers=headers)\n",
    "\n",
    "\n",
    "def text_to_speech(text):\n",
    "    \"\"\"将指定的文本转换为语音并播放\"\"\"\n",
    "    data = {}\n",
    "    data['langType'] = 'zh-CHS'\n",
    "    salt = str(uuid.uuid1())\n",
    "    signStr = APP_KEY + text + salt + APP_SECRET\n",
    "    sign = encrypt(signStr)\n",
    "    data['appKey'] = APP_KEY\n",
    "    data['q'] = text\n",
    "    data['salt'] = salt\n",
    "    data['sign'] = sign\n",
    "\n",
    "    response = do_request(data)\n",
    "    contentType = response.headers['Content-Type']\n",
    "    if contentType == \"audio/mp3\":\n",
    "        millis = int(round(time.time() * 1000))\n",
    "        filePath = \"\" + str(millis) + \".mp3\"\n",
    "        with open(filePath, 'wb') as fo:\n",
    "            fo.write(response.content)\n",
    "        print(\"文件保存路径：\" + filePath)\n",
    "        playsound(filePath)  # 播放语音\n",
    "    else:\n",
    "        print(response.content)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text = \"\"\"\n",
    "In their research paper, the authors propose a novel probe methodology for detecting implicit biases in large language models (LLMs). They introduce a logistic probe trained using maximum likelihood estimation to encode binary preference between contextualized embeddings. The veracity analysis demonstrates the superior performance of the probe compared to existing baselines, with middle layers of the model consistently performing the best. The bias analysis reveals sociodemographic biases in LLM embeddings, including biases in nationality, politics, religion, and gender. Notably, LLMs exhibit biases favoring Western and African countries in the nationality domain and leftist views and libertarianism in politics. The findings highlight the presence of biases in LLM latent representations despite safety measures. This research contributes to understanding and addressing biases in LLMs, emphasizing the need for further research and improvement.\n",
    "\n",
    "\"\"\"\n",
    "    y = text_to_speech(text)\n",
    "    print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 提取PDF图片"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件名:data/3200101550-王匡-第六次作业.pdf, 页数: 5, 对象: 21\n",
      "提取图片 1 -> 3200101550-王匡-第六次作业.pdf_img1.png\n",
      "提取了1张图片\n",
      "提取图片 2 -> 3200101550-王匡-第六次作业.pdf_img2.png\n",
      "提取了2张图片\n",
      "提取图片 3 -> 3200101550-王匡-第六次作业.pdf_img3.png\n",
      "提取了3张图片\n",
      "提取图片 4 -> 3200101550-王匡-第六次作业.pdf_img4.png\n",
      "提取了4张图片\n",
      "提取图片 5 -> 3200101550-王匡-第六次作业.pdf_img5.png\n",
      "提取了5张图片\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "def save_pdf_img(path,save_path):\n",
    "    '''\n",
    "    path: pdf的路径\n",
    "    save_path : 图片存储的路径\n",
    "    '''\n",
    "    # 使用正则表达式来查找图片\n",
    "    checkXO = r\"/Type(?= */XObject)\"\n",
    "    checkIM = r\"/Subtype(?= */Image)\"\n",
    "    # 打开pdf\n",
    "    doc = fitz.open(path)\n",
    "    # 图片计数\n",
    "    imgcount = 0\n",
    "    # 获取对象数量长度\n",
    "    lenXREF = doc.xref_length()\n",
    "\n",
    "    # 打印PDF的信息\n",
    "    print(\"文件名:{}, 页数: {}, 对象: {}\".format(path, len(doc), lenXREF - 1))\n",
    "\n",
    "\n",
    "    # 遍历每一个图片对象\n",
    "    for i in range(1, lenXREF):\n",
    "        # 定义对象字符串\n",
    "        text = doc.xref_object(i)\n",
    "        # print(i,text)\n",
    "        isXObject = re.search(checkXO, text)\n",
    "        # 使用正则表达式查看是否是图片\n",
    "        isImage = re.search(checkIM, text)\n",
    "        # 如果不是对象也不是图片，则continue\n",
    "        if not isXObject or not isImage:\n",
    "            continue\n",
    "        imgcount += 1\n",
    "        # 根据索引生成图像\n",
    "        pix = fitz.Pixmap(doc, i)\n",
    "        # 根据pdf的路径生成图片的名称\n",
    "        new_name = path.split('/')[-1].replace('\\\\', '_') + \"_img{}.png\".format(imgcount)\n",
    "        new_name = new_name.replace(':', '')\n",
    "        print(\"提取图片 {} -> {}\".format(imgcount, new_name))\n",
    "        # 如果pix.n<5,可以直接存为PNG\n",
    "        if pix.n < 5:\n",
    "            # pix.writePNG(os.path.join(save_path, new_name))\n",
    "            pix.save(os.path.join(save_path, new_name))\n",
    "        # 否则先转换CMYK\n",
    "        else:\n",
    "            pix0 = fitz.Pixmap(fitz.csRGB, pix)\n",
    "            # pix0.writePNG(os.path.join(save_path, new_name))\n",
    "            pix0.save(os.path.join(save_path, new_name))\n",
    "            pix0 = None\n",
    "        # 释放资源\n",
    "        pix = None\n",
    "        print(\"提取了{}张图片\".format(imgcount))\n",
    "\n",
    "\n",
    "# 提取每一页的图片对象单独保存\n",
    "def muExtractImages(pdf_name, pic_save_path):\n",
    "    doc = fitz.open(pdf_name)\n",
    "    for itm,page in enumerate(doc):\n",
    "        try:\n",
    "            tupleImage = page.get_images()\n",
    "            print(tupleImage)\n",
    "            for xref0 in tupleImage:  # 取第一个元组\n",
    "                xref = xref0[0]  # 最终取得xref  ok\n",
    "                img = doc.extract_image(xref)  # 获取文件扩展名，图片内容 等信息\n",
    "                imageFilename = os.path.join(pic_save_path, str(itm) + '_' + str(xref) + '.' + img['ext'])\n",
    "                imgout = open(imageFilename, 'wb')  # byte方式新建图片\n",
    "                imgout.write(img[\"image\"])  # 当前提取的图片写入磁盘\n",
    "                imgout.close()\n",
    "        except:\n",
    "            continue\n",
    "    doc.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # pdf路径\n",
    "    path = r'data/3200101550-王匡-第六次作业.pdf'\n",
    "    pic_path = r'./res/pic'\n",
    "    # 创建保存图片的文件夹\n",
    "    # if os.path.exists(pic_path):\n",
    "    #     print(\"文件夹已存在，请重新创建新文件夹！\")\n",
    "    #     raise SystemExit\n",
    "    # else:\n",
    "    #     os.mkdir(pic_path)\n",
    "    # m = pdf2pic(path, pic_path)\n",
    "    # muExtractImages(path,pic_path)\n",
    "    save_pdf_img(path,pic_path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path,convert_from_bytes\n",
    "import tempfile\n",
    "from pdf2image.exceptions import PDFInfoNotInstalledError, PDFPageCountError, PDFSyntaxError\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = r'./data/111.pdf' # pdf文件路径\n",
    "dir_path = r'./res'\n",
    "\n",
    "def pdf2image3(file_path, dir_path):\n",
    "    images = convert_from_bytes(open(file_path, 'rb').read(),\n",
    "                                poppler_path=poppler_path)\n",
    "    for image in images:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        image.save(dir_path + f'\\img_{images.index(image)}.png', 'PNG')\n",
    "poppler_path = r'D:\\poppler\\poppler-23.11.0\\Library\\bin'\n",
    "pdf2image3(file_path, dir_path)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import re\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "# Your text containing the table\n",
    "text_with_table = r\"\"\"\n",
    "Some text before the table.\n",
    "\n",
    "\\begin{table}\n",
    "\\begin{tabular}{c|c|c|c|c|c} \\hline case & Fig. & on shortcut & on \\(\\mathcal{F}\\) & error (\\%) & remark \\\\ \\hline \\hline original [1] & Fig. 2(a) & 1 & 1 & **6.61** & \\\\ \\hline \\multirow{3}{*}{\\begin{tabular}{c} constant \\\\ scaling \\\\ \\end{tabular} } & \\multirow{3}{*}{Fig. 2(b)} & 0 & 1 & fail & This is a plain net \\\\  & & 0.5 & 1 & fail & \\\\  & & 0.5 & 0.5 & 12.35 & frozen gating \\\\ \\hline \\multirow{3}{*}{\\begin{tabular}{c} exclusive \\\\ gating \\\\ \\end{tabular} } & \\multirow{3}{*}{Fig. 2(c)} & \\(1-g(\\mathbf{x})\\) & \\(g(\\mathbf{x})\\) & fail & init \\(b_{g}\\)=0 to \\(-5\\) \\\\  & & \\(1-g(\\mathbf{x})\\) & \\(g(\\mathbf{x})\\) & 8.70 & init \\(b_{g}\\)=-6 \\\\  & & \\(1-g(\\mathbf{x})\\) & \\(g(\\mathbf{x})\\) & 9.81 & init \\(b_{g}\\)=-7 \\\\ \\hline \\multirow{3}{*}{\n",
    "\\begin{tabular}{c} shortcut-only \\\\ gating \\\\ \\end{tabular} } & \\multirow{3}{*}{Fig. 2(d)} & \\(1-g(\\mathbf{x})\\) & 1 & 12.86 & init \\(b_{g}\\)=0 \\\\  & & \\(1-g(\\mathbf{x})\\) & 1 & 6.91 & init \\(b_{g}\\)=-6 \\\\ \\hline\n",
    "1\\(\\times\\)1 conv shortcut & Fig. 2(e) & 1\\(\\times\\)1 conv & 1 & 12.22 & \\\\ \\hline dropout shortcut & Fig. 2(f) & dropout 0.5 & 1 & fail & \\\\ \\hline \\end{tabular}\n",
    "\\end{table}\n",
    "\n",
    "Some text after the table.\n",
    "\"\"\"\n",
    "\n",
    "# Use regular expressions to find the table content\n",
    "def transfer_tables(text_with_tables):\n",
    "    # Find all occurrences of LaTeX table environments\n",
    "    matches = re.finditer(r'\\\\begin{table}(.*?)\\\\end{table}', text_with_tables, re.DOTALL)\n",
    "\n",
    "    for match in matches:\n",
    "        table_content = match.group(1)\n",
    "        # 将 \\multirow 中的内容复制到每一行\n",
    "        table_content = re.sub(r'\\\\multirow\\{\\d\\}\\{\\*\\}\\{(.*?)\\}', r'\\1', table_content)\n",
    "        # 分割表格到行\n",
    "        table_data = [line.split(\"&\") for line in table_content.strip().split(\"\\\\hline\")[1:]]\n",
    "\n",
    "        markdown_table = tabulate(table_data, headers=\"firstrow\", tablefmt=\"pipe\")\n",
    "\n",
    "        # Replace the LaTeX table with the Markdown table in the original text\n",
    "        text_with_tables = text_with_tables.replace(match.group(0), markdown_table)\n",
    "\n",
    "    return text_with_tables\n",
    "\n",
    "def latex2md_math(text):\n",
    "    \"\"\"\n",
    "    convert latex math to markdown math\n",
    "    Args:\n",
    "        text: text with latex math\n",
    "\n",
    "    Returns: text with markdown math\n",
    "\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\\\\\[(.*?)\\\\\\]',r'$$\\1$$',text)\n",
    "    text = re.sub(r'\\\\\\((.*?)\\\\\\)',r'$\\1$',text)\n",
    "    return text\n",
    "\n",
    "md_path = \"./res/raw_mmd/111.mmd\"\n",
    "out_dir = \"data\"\n",
    "\n",
    "with open(md_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = latex2md_math(text)\n",
    "text_with_table = transfer_tables(text)\n",
    "with open(os.path.join(out_dir, '111.md'), 'w', encoding='utf-8') as f:\n",
    "    f.write(text_with_table)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| cell1   | cell2   | cell3   |\n",
      "|:--------|:--------|:--------|\n",
      "| cell4   | cell5   | cell6   |\n",
      "| cell7   | cell8   | cell9   |\n"
     ]
    }
   ],
   "source": [
    "def clean_content(content):\n",
    "    # Remove all \\hline\n",
    "    clean = re.sub(r'\\\\hline', '', content)\n",
    "\n",
    "    # Remove leading and trailing non-alphabetic characters\n",
    "    clean = re.sub(r'^\\W+|\\W+$', '', clean)\n",
    "\n",
    "    return clean\n",
    "\n",
    "def latex_table_to_markdown(latex_table):\n",
    "    # 匹配LaTeX表格内容\n",
    "    match = re.search(r'\\\\begin{tabular}(.*?)\\\\hline(.*?)\\\\\\\\(.*?)\\\\end{tabular}', latex_table, re.DOTALL)\n",
    "\n",
    "    if not match:\n",
    "        return \"Invalid LaTeX table\"\n",
    "\n",
    "    # 获取表格列数和内容\n",
    "    column_definition = match.group(2)\n",
    "    table_content = match.group(3)\n",
    "    # 解析表格列定义\n",
    "    columns = [col.strip() for col in column_definition.split('&') if col.strip()]\n",
    "    table_content = clean_content(table_content)\n",
    "\n",
    "    # 解析表格内容\n",
    "    table_data = [line.split('&') for line in table_content.strip().split('\\\\\\\\')]\n",
    "    # 替换\\multirow\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[i])):\n",
    "            cell_content = table_data[i][j].strip()\n",
    "            match_multirow = re.match(r'\\\\multirow{(\\d+)}{(.*?)}', cell_content)\n",
    "            if match_multirow:\n",
    "                # 获取\\multirow的行数和内容\n",
    "                num_rows = int(match_multirow.group(1))\n",
    "                multirow_content = match_multirow.group(2)\n",
    "                # 在后续行中插入空白单元格\n",
    "                for k in range(1, num_rows):\n",
    "                    if i + k < len(table_data):\n",
    "                        table_data[i + k].insert(j, '')\n",
    "                    else:\n",
    "                        # 如果超出了表格行数，添加新行\n",
    "                        table_data.append([''] * len(columns))\n",
    "                        table_data[i + k][j] = ''\n",
    "                table_data[i][j] = multirow_content\n",
    "\n",
    "\n",
    "    # 生成Markdown表格\n",
    "    markdown_table = tabulate(table_data, headers=columns, tablefmt=\"pipe\")\n",
    "\n",
    "    return markdown_table\n",
    "\n",
    "text_with_table = r\"\"\"\n",
    "Some text before the table.\n",
    "\n",
    "\\begin{table}\n",
    "\\begin{tabular}{c|c|c|c|c|c} \\hline case & Fig. & on shortcut & on \\(\\mathcal{F}\\) & error (\\%) & remark \\\\ \\hline \\hline original [1] & Fig. 2(a) & 1 & 1 & **6.61** & \\\\ \\hline \\multirow{3}{*}{\\begin{tabular}{c} constant \\\\ scaling \\\\ \\end{tabular} } & \\multirow{3}{*}{Fig. 2(b)} & 0 & 1 & fail & This is a plain net \\\\  & & 0.5 & 1 & fail & \\\\  & & 0.5 & 0.5 & 12.35 & frozen gating \\\\ \\hline \\multirow{3}{*}{\\begin{tabular}{c} exclusive \\\\ gating \\\\ \\end{tabular} } & \\multirow{3}{*}{Fig. 2(c)} & \\(1-g(\\mathbf{x})\\) & \\(g(\\mathbf{x})\\) & fail & init \\(b_{g}\\)=0 to \\(-5\\) \\\\  & & \\(1-g(\\mathbf{x})\\) & \\(g(\\mathbf{x})\\) & 8.70 & init \\(b_{g}\\)=-6 \\\\  & & \\(1-g(\\mathbf{x})\\) & \\(g(\\mathbf{x})\\) & 9.81 & init \\(b_{g}\\)=-7 \\\\ \\hline \\multirow{3}{*}{\n",
    "\\begin{tabular}{c} shortcut-only \\\\ gating \\\\ \\end{tabular} } & \\multirow{3}{*}{Fig. 2(d)} & \\(1-g(\\mathbf{x})\\) & 1 & 12.86 & init \\(b_{g}\\)=0 \\\\  & & \\(1-g(\\mathbf{x})\\) & 1 & 6.91 & init \\(b_{g}\\)=-6 \\\\ \\hline\n",
    "1\\(\\times\\)1 conv shortcut & Fig. 2(e) & 1\\(\\times\\)1 conv & 1 & 12.22 & \\\\ \\hline dropout shortcut & Fig. 2(f) & dropout 0.5 & 1 & fail & \\\\ \\hline \\end{tabular}\n",
    "\\end{table}\n",
    "\n",
    "Some text after the table.\n",
    "\"\"\"\n",
    "\n",
    "latex_table = \"\"\"\n",
    "\\\\begin{tabular}{ |c|c|c| }\n",
    "\\\\hline\n",
    "cell1 & cell2 & cell3 \\\\\\\\\n",
    "\\\\hline\n",
    "cell4 & cell5 & cell6 \\\\\\\\\n",
    "\\\\hline\n",
    "cell7 & cell8 & cell9 \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\end{tabular}\n",
    "\"\"\"\n",
    "text_with_table = latex_table_to_markdown(latex_table)\n",
    "print(text_with_table)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'groups'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 69\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[0;32m     56\u001B[0m latex_table \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;132;01m{tabular}\u001B[39;00m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m|c|c|c|}\u001B[39m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mhline\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mend\u001B[39m\u001B[38;5;132;01m{tabular}\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m---> 69\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mlatex_table_to_markdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlatex_table\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[1;32mIn[5], line 33\u001B[0m, in \u001B[0;36mlatex_table_to_markdown\u001B[1;34m(latex_table)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j, cell \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(row):\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmultirow\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m cell \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmulticolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m cell:\n\u001B[0;32m     31\u001B[0m         \u001B[38;5;66;03m# Extract the number of rows/columns and the actual content\u001B[39;00m\n\u001B[0;32m     32\u001B[0m         \u001B[38;5;66;03m# This is a simplified example, and would need to be adapted based on the specific LaTeX formatting used\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m         count, content \u001B[38;5;241m=\u001B[39m \u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mmulti(?:row|column)\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m{\u001B[39;49m\u001B[38;5;124;43m(\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43md+)\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m}\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m{\u001B[39;49m\u001B[38;5;124;43m.*?\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m}\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m{\u001B[39;49m\u001B[38;5;124;43m(.*?)\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m}\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m()\n\u001B[0;32m     34\u001B[0m         count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(count)\n\u001B[0;32m     35\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmultirow\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m cell:\n\u001B[0;32m     36\u001B[0m             \u001B[38;5;66;03m# Merge vertically with rows below\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'groups'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_content(content):\n",
    "    # Remove all \\hline and trim spaces\n",
    "    clean = re.sub(r'\\\\hline', '', content).strip()\n",
    "    # Remove leading and trailing non-alphabetic characters\n",
    "    clean = re.sub(r'^\\W+|\\W+$', '', clean)\n",
    "    return clean\n",
    "\n",
    "def latex_table_to_markdown(latex_table):\n",
    "    # Match LaTeX table content\n",
    "    match = re.search(r'\\\\begin{tabular}(.*?)\\\\hline(.*?)\\\\\\\\(.*?)\\\\end{tabular}', latex_table, re.DOTALL)\n",
    "    if not match:\n",
    "        return \"Invalid LaTeX table\"\n",
    "\n",
    "    # Get table column definitions and content\n",
    "    column_definition = match.group(2)\n",
    "    table_content = match.group(3)\n",
    "\n",
    "    # Process column definitions\n",
    "    columns = [col.strip() for col in column_definition.split('&') if col.strip()]\n",
    "    table_content = clean_content(table_content)\n",
    "\n",
    "    # Process table content\n",
    "    table_data = [line.split('&') for line in table_content.split('\\\\\\\\') if line.strip()]\n",
    "\n",
    "    # Handle multirow and multicolumn\n",
    "    for i, row in enumerate(table_data):\n",
    "        for j, cell in enumerate(row):\n",
    "            if \"\\\\multirow\" in cell or \"\\\\multicolumn\" in cell:\n",
    "                # Extract the number of rows/columns and the actual content\n",
    "                # This is a simplified example, and would need to be adapted based on the specific LaTeX formatting used\n",
    "                count, content = re.match(r'\\\\multi(?:row|column)\\{(\\d+)\\}\\{.*?\\}\\{(.*?)\\}', cell).groups()\n",
    "                count = int(count)\n",
    "                if \"\\\\multirow\" in cell:\n",
    "                    # Merge vertically with rows below\n",
    "                    for k in range(1, count):\n",
    "                        if i + k < len(table_data):\n",
    "                            table_data[i + k][j] = content\n",
    "                elif \"\\\\multicolumn\" in cell:\n",
    "                    # Merge horizontally with cells to the right\n",
    "                    row[j:j+count] = [' '.join(row[j:j+count])]\n",
    "                    # Adjust the rest of the row if necessary\n",
    "                    if len(row) > len(columns):\n",
    "                        row.pop(j+1)\n",
    "\n",
    "    # Convert to Markdown\n",
    "    markdown_table = \"| \" + \" | \".join(columns) + \" |\\n\"\n",
    "    markdown_table += \"| \" + \" | \".join([\"---\"] * len(columns)) + \" |\\n\"\n",
    "    for row in table_data:\n",
    "        markdown_table += \"| \" + \" | \".join(row) + \" |\\n\"\n",
    "\n",
    "    return markdown_table\n",
    "\n",
    "# Example usage\n",
    "latex_table = \"\"\"\n",
    "\\\\begin{tabular}{|c|c|c|}\n",
    "\\\\hline\n",
    "Header1 & Header2 & Header3 \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\multirow{2}{*}{Row1-1} & Row1-2 & Row1-3 \\\\\\\\\n",
    "                         & Row2-2 & Row2-3 \\\\\\\\\n",
    "\\\\hline\n",
    "Row3-1 & \\\\multicolumn{2}{c|}{Row3-2 and 3} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\end{tabular}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table_to_markdown(latex_table))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.pdf\n",
      "data\\111.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": "('111', '.pdf', '111raw_.mmd')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "x = \"data/111.pdf\"\n",
    "print(os.path.basename(x))\n",
    "x= Path(x)\n",
    "print(x)\n",
    "x.stem,x.suffix,x.stem + \"raw_\" + \".mmd\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'./img/111.pdf'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"./img/\" + os.path.basename(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "if {}:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

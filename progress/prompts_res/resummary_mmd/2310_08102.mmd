# EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation

## Abstract
The paper proposes a framework called Evaluation-guided Iterative Plan Extraction (EIPE-text) for generating coherent and relevant long-form narrative texts. The framework includes plan extraction, learning, and inference stages. The authors introduce a question-answer based evaluation mechanism to evaluate and refine the extracted plans. The evaluation results, including both GPT-4-based evaluations and human evaluations, show that the EIPE-text framework can generate more coherent and relevant long-form narratives. The code for the framework will be released in the future.

## Introduction
Generating long-form narratives that maintain coherence and relevance remains a challenge for large language models. The authors propose the Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation (EIPE-text) framework, which leverages a learned planner to generate high-quality plans for narrative text generation. The authors evaluate the effectiveness of EIPE-text in the novel and storytelling domains, and it outperforms state-of-the-art models in terms of coherence and relevance.

## Method
The EIPE-text framework involves plan extraction, learning, and inference stages. In the plan extraction stage, plans are extracted from the narrative corpus using LLM. QA-pairs are generated to evaluate and refine the plan, and the plan is iteratively improved based on the evaluation. In the learning stage, an LLM planner is trained using the extracted plan as input. In the inference stage, the planner generates a plan and the narrative is generated from the plan.

## Experiment
The experiment involves plan extraction and inference stages using Azure Openai GPT-4 as the language model. The novel dataset consists of 1292 stories, and the storytelling dataset includes 2468 TED Talks. The results show that the EIPE-text framework outperforms baseline models in terms of coherence, relevance, and overall quality of the generated narrative.

## Analysis
The analysis section explores the key aspects of designing an effective planner and provides an experimental analysis of the plan refinement process. It compares different planner configurations and demonstrates the effectiveness of hierarchical generation in narrative generation. The refinement process is shown to converge quickly with self-refinement. A case study highlights the advantages of using in-context learning with plans.

## Related Work
Previous research in long-form narrative text generation has explored various approaches, but the results have not been satisfactory. The authors build upon previous work by using LLM to automatically mine the plan and train a good planner, making human-AI co-writing easier.

## Limitations
The limitations mentioned in the paper include the reliance on models with strong reasoning capabilities for question-answering and the data-driven nature of the framework, which may not improve out-of-distribution performance.

## Initialized Plan
This section discusses the various products in daily life that contain pig parts. It highlights the significance of pig usage in the Netherlands and presents research on products in categories such as bathroom items, food items, construction materials, household items, meat products, beverages, and others.

## QASiNa: Religious Domain Question Answering using Sirah Nabawiyah
This section evaluates the performance of large language models in the religious domain, specifically in the Islamic religion. It proposes a new dataset called QASiNa compiled from Sirah Nabawiyah literatures in the Indonesian language. The XLM-R model performs the best on the QASiNa dataset, outperforming Chat GPT-3.5 and GPT-4 models.

## Conclusion
The paper introduces the EIPE-text framework for generating coherent and relevant long-form narrative texts. It highlights the potential of using LLMs to assist human writers and suggests further research directions. The QASiNa dataset is made publicly available for the research community.

## Acknowledgment
The authors express gratitude to the funding provider and the domain experts who assisted in validating the datasets.